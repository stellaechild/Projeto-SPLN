{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c211ab9c",
   "metadata": {},
   "source": [
    "# Fine-tuning a model for Sentence Similarity and Information Retrieval\n",
    "\n",
    "In this notebook, we will fine-tune a sentence transformer model for document similarity tasks, specifically for the RepositoriUM collection. We'll use a pre-trained model and fine-tune it on pairs of document abstracts with similarity scores.\n",
    "\n",
    "The completed system will allow us to:\n",
    "1. Process document collections from RepositoriUM\n",
    "2. Train a similarity model on document pairs\n",
    "3. Retrieve relevant documents based on a query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b235e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (3.3.2)\n",
      "Requirement already satisfied: transformers in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (4.52.4)\n",
      "Requirement already satisfied: sentence-transformers in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (4.1.0)\n",
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (1.26.0)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (4.67.1)\n",
      "Requirement already satisfied: evaluate in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (0.4.3)\n",
      "Requirement already satisfied: huggingface_hub in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (0.32.4)\n",
      "Requirement already satisfied: torch in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (2.6.0)\n",
      "Requirement already satisfied: accelerate>=0.26.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (1.7.0)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from datasets) (3.13.3)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from datasets) (19.0.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: requests>=2.32.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: xxhash in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\n",
      "Requirement already satisfied: aiohttp in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from datasets) (3.10.4)\n",
      "Requirement already satisfied: packaging in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from datasets) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from huggingface_hub) (4.12.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from huggingface_hub) (1.1.3)\n",
      "Requirement already satisfied: scikit-learn in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from sentence-transformers) (1.5.2)\n",
      "Requirement already satisfied: scipy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from sentence-transformers) (1.14.1)\n",
      "Requirement already satisfied: Pillow in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from sentence-transformers) (10.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch) (3.1.5)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: psutil in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from accelerate>=0.26.0) (7.0.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from aiohttp->datasets) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from aiohttp->datasets) (1.18.3)\n",
      "Requirement already satisfied: idna>=2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from yarl<2.0,>=1.0->aiohttp->datasets) (3.10)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from yarl<2.0,>=1.0->aiohttp->datasets) (0.2.1)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "!pip install datasets transformers matplotlib sentence-transformers pandas numpy tqdm evaluate huggingface_hub torch 'accelerate>=0.26.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ac5a838",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "import sentence_transformers\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbe6bdfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.utils import send_example_telemetry\n",
    "\n",
    "send_example_telemetry(\"sentence_similarity_notebook\", framework=\"pytorch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c5a700",
   "metadata": {},
   "source": [
    "## Configuring the Model\n",
    "\n",
    "We'll set the parameters for our model training. For best results in sentence similarity tasks, we should use a pre-trained sentence-transformer model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82f536d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model configuration\n",
    "model_checkpoint = \"paraphrase-multilingual-MiniLM-L12-v2\"\n",
    "batch_size = 16\n",
    "max_length = 512\n",
    "\n",
    "# Training parameters\n",
    "num_epochs = 3\n",
    "warmup_ratio = 0.1\n",
    "learning_rate = 2e-5\n",
    "weight_decay = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01fa71fa",
   "metadata": {},
   "source": [
    "## Loading the Dataset\n",
    "\n",
    "First, we need to load the training data that was created by our `process_data.py` script.\n",
    "This data consists of pairs of document abstracts with similarity scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d392025c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 500 document pairs\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "data_dir = Path(\"data\")\n",
    "train_file = data_dir / \"training_data.json\"\n",
    "\n",
    "try:\n",
    "    with open(train_file, 'r', encoding='utf-8') as f:\n",
    "        training_data = json.load(f)\n",
    "\n",
    "    print(f\"Loaded {len(training_data)} document pairs\")\n",
    "    \n",
    "    train_df = pd.DataFrame([\n",
    "        {\"abstract1\": item[0], \"abstract2\": item[1], \"similarity\": float(item[2])}\n",
    "        for item in training_data\n",
    "    ])\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error loading training data: {e}\")\n",
    "    print(\"Please run process_data.py first to create the training data, or check the file path\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcbe6dd8",
   "metadata": {},
   "source": [
    "Let's examine the distribution of similarity scores to understand our data better:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd7dbd0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min similarity: 0.0\n",
      "Max similarity: 0.3\n",
      "Mean similarity: 0.1371096928071928\n",
      "Median similarity: 0.06666666666666667\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if len(train_df) > 0:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(train_df['similarity'], bins=20)\n",
    "    plt.title('Distribution of Similarity Scores')\n",
    "    plt.xlabel('Similarity Score')\n",
    "    plt.ylabel('Count')\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Min similarity: {train_df['similarity'].min()}\")\n",
    "    print(f\"Max similarity: {train_df['similarity'].max()}\")\n",
    "    print(f\"Mean similarity: {train_df['similarity'].mean()}\")\n",
    "    print(f\"Median similarity: {train_df['similarity'].median()}\")\n",
    "else:\n",
    "    print(\"Not enough data to display similarity distribution.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9d6a63",
   "metadata": {},
   "source": [
    "Now, let's prepare the data for training by splitting it into training and validation sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ad61ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: 400 pairs\n",
      "Validation data: 100 pairs\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "if len(train_df) < 10:\n",
    "    print(\"Warning: Not enough data for a meaningful split. Consider generating more data.\")\n",
    "    # Create a simple split for demonstration\n",
    "    train_data = train_df.iloc[:int(len(train_df)*0.8)]\n",
    "    val_data = train_df.iloc[int(len(train_df)*0.8):]\n",
    "else:\n",
    "    # Split data into train and validation sets\n",
    "    train_data, val_data = train_test_split(train_df, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training data: {len(train_data)} pairs\")\n",
    "print(f\"Validation data: {len(val_data)} pairs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b5d629",
   "metadata": {},
   "source": [
    "## Preparing the Model for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d43bc49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model successfully loaded: SentenceTransformer(\n",
      "  (0): Transformer({'max_seq_length': 128, 'do_lower_case': False}) with Transformer model: BertModel \n",
      "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
      ")\n",
      "Model is on device: cpu\n",
      "Prepared 400 training examples and 100 validation examples\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, InputExample, losses\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import time\n",
    "\n",
    "device_str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "try:\n",
    "    model = SentenceTransformer(model_checkpoint, device=device_str)\n",
    "    print(f\"Model successfully loaded: {model}\")\n",
    "    \n",
    "    print(f\"Model is on device: {next(model.parameters()).device}\")\n",
    "\n",
    "    train_examples = []\n",
    "    for _, row in train_data.iterrows():\n",
    "        abstract1 = str(row['abstract1']) if not isinstance(row['abstract1'], str) else row['abstract1']\n",
    "        abstract2 = str(row['abstract2']) if not isinstance(row['abstract2'], str) else row['abstract2']\n",
    "        \n",
    "        train_examples.append(InputExample(\n",
    "            texts=[abstract1, abstract2],\n",
    "            label=float(row['similarity'])\n",
    "        ))\n",
    "\n",
    "    val_examples = []\n",
    "    for _, row in val_data.iterrows():\n",
    "        abstract1 = str(row['abstract1']) if not isinstance(row['abstract1'], str) else row['abstract1']\n",
    "        abstract2 = str(row['abstract2']) if not isinstance(row['abstract2'], str) else row['abstract2']\n",
    "        \n",
    "        val_examples.append(InputExample(\n",
    "            texts=[abstract1, abstract2],\n",
    "            label=float(row['similarity'])\n",
    "        ))\n",
    "\n",
    "    # Define a custom collate function for InputExample objects\n",
    "    def collate_fn(batch):\n",
    "        texts = [example.texts for example in batch]\n",
    "        labels = [example.label for example in batch]\n",
    "        return {\"texts\": texts, \"labels\": torch.tensor(labels)}\n",
    "\n",
    "    # Create DataLoader for training with the custom collate function\n",
    "    train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=batch_size, collate_fn=collate_fn)\n",
    "\n",
    "    evaluator = EmbeddingSimilarityEvaluator(\n",
    "        sentences1=[ex.texts[0] for ex in val_examples],\n",
    "        sentences2=[ex.texts[1] for ex in val_examples],\n",
    "        scores=[ex.label for ex in val_examples]\n",
    "    )\n",
    "    \n",
    "    print(f\"Prepared {len(train_examples)} training examples and {len(val_examples)} validation examples\")\n",
    "except Exception as e:\n",
    "    print(f\"Error preparing model: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63c834f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model successfully loaded: SentenceTransformer(\n",
      "  (0): Transformer({'max_seq_length': 128, 'do_lower_case': False}) with Transformer model: BertModel \n",
      "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
      ")\n",
      "Model is on device: cpu\n",
      "Prepared 400 training examples and 100 validation examples\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, InputExample, losses\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import time\n",
    "\n",
    "device_str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "try:\n",
    "    model = SentenceTransformer(model_checkpoint, device=device_str)\n",
    "    print(f\"Model successfully loaded: {model}\")\n",
    "    \n",
    "    print(f\"Model is on device: {next(model.parameters()).device}\")\n",
    "\n",
    "    train_examples = []\n",
    "    for _, row in train_data.iterrows():\n",
    "        abstract1 = str(row['abstract1']) if not isinstance(row['abstract1'], str) else row['abstract1']\n",
    "        abstract2 = str(row['abstract2']) if not isinstance(row['abstract2'], str) else row['abstract2']\n",
    "        \n",
    "        train_examples.append(InputExample(\n",
    "            texts=[abstract1, abstract2],\n",
    "            label=float(row['similarity'])\n",
    "        ))\n",
    "\n",
    "    val_examples = []\n",
    "    for _, row in val_data.iterrows():\n",
    "        abstract1 = str(row['abstract1']) if not isinstance(row['abstract1'], str) else row['abstract1']\n",
    "        abstract2 = str(row['abstract2']) if not isinstance(row['abstract2'], str) else row['abstract2']\n",
    "        \n",
    "        val_examples.append(InputExample(\n",
    "            texts=[abstract1, abstract2],\n",
    "            label=float(row['similarity'])\n",
    "        ))\n",
    "\n",
    "    # Define a custom collate function for InputExample objects\n",
    "    def collate_fn(batch):\n",
    "        texts = [example.texts for example in batch]\n",
    "        labels = [example.label for example in batch]\n",
    "        return {\"texts\": texts, \"labels\": torch.tensor(labels)}\n",
    "\n",
    "    # Create DataLoader for training with the custom collate function\n",
    "    train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=batch_size, collate_fn=collate_fn)\n",
    "\n",
    "    evaluator = EmbeddingSimilarityEvaluator(\n",
    "        sentences1=[ex.texts[0] for ex in val_examples],\n",
    "        sentences2=[ex.texts[1] for ex in val_examples],\n",
    "        scores=[ex.label for ex in val_examples]\n",
    "    )\n",
    "    \n",
    "    print(f\"Prepared {len(train_examples)} training examples and {len(val_examples)} validation examples\")\n",
    "except Exception as e:\n",
    "    print(f\"Error preparing model: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93629c06",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82d367c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training at 2025-06-17 18:51:21.892600\n",
      "Total steps: 75, Warmup steps: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='71' max='75' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [71/75 11:03 < 00:38, 0.10 it/s, Epoch 2.80/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Pearson Cosine</th>\n",
       "      <th>Spearman Cosine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.081050</td>\n",
       "      <td>0.076317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.140475</td>\n",
       "      <td>0.133713</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import losses\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Create an output directory for saving the model\n",
    "output_dir = os.path.join(\"information_retrieval/output\", \"repositorium-similarity-model\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Calculate number of warmup steps\n",
    "num_training_steps = len(train_dataloader) * num_epochs\n",
    "warmup_steps = int(num_training_steps * warmup_ratio)\n",
    "\n",
    "# Define loss function (CosineSimilarityLoss for regression of similarity scores)\n",
    "train_loss = losses.CosineSimilarityLoss(model=model)\n",
    "\n",
    "# Start training\n",
    "print(f\"Starting training at {datetime.now()}\")\n",
    "print(f\"Total steps: {num_training_steps}, Warmup steps: {warmup_steps}\")\n",
    "\n",
    "try:\n",
    "    model.fit(\n",
    "        train_objectives=[(train_dataloader, train_loss)],\n",
    "        evaluator=evaluator,\n",
    "        epochs=num_epochs,\n",
    "        warmup_steps=warmup_steps,\n",
    "        weight_decay=weight_decay, \n",
    "        output_path=output_dir,\n",
    "        optimizer_params={'lr': learning_rate},\n",
    "        show_progress_bar=True,\n",
    "        evaluation_steps=25,\n",
    "        save_best_model=True\n",
    "    )\n",
    "    \n",
    "    print(f\"Training completed. Model saved to {output_dir}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error during training: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1dbdf07",
   "metadata": {},
   "source": [
    "## Evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdd837c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded best model from information_retrieval/output/repositorium-similarity-model\n",
      "Evaluating model on validation set...\n",
      "Pearson correlation: 0.1495 (p=0.1376)\n",
      "Spearman correlation: 0.1562 (p=0.1207)\n",
      "\n",
      "Sample predictions:\n",
      "Text 1: ['the 2d convection-diffusion is a well-known prob...\n",
      "Text 2: ['a visualizao de relatrios de meios complement...\n",
      "Gold score: 0.1000, Predicted: 0.1504\n",
      "--------------------------------------------------------------------------------\n",
      "Text 1: ['on a business context, it is responsibility of t...\n",
      "Text 2: ['the reconstruction of genomic-scale metabolic mo...\n",
      "Gold score: 0.0000, Predicted: 0.0415\n",
      "--------------------------------------------------------------------------------\n",
      "Text 1: ['o koha  um software com interface web para gest...\n",
      "Text 2: ['devido  elevada proliferao tecnolgica, exist...\n",
      "Gold score: 0.3000, Predicted: 0.1817\n",
      "--------------------------------------------------------------------------------\n",
      "Text 1: ['real-time monitoring has become one of the most ...\n",
      "Text 2: ['a sade constitui um direito inegvel dos cidad...\n",
      "Gold score: 0.0000, Predicted: 0.0970\n",
      "--------------------------------------------------------------------------------\n",
      "Text 1: ['ao longo dos ltimos anos, tem-se assistido a um...\n",
      "Text 2: ['a deteo de danos na estrutura externa de vecu...\n",
      "Gold score: 0.0667, Predicted: -0.0412\n",
      "--------------------------------------------------------------------------------\n",
      "Pearson correlation: 0.1495 (p=0.1376)\n",
      "Spearman correlation: 0.1562 (p=0.1207)\n",
      "\n",
      "Sample predictions:\n",
      "Text 1: ['the 2d convection-diffusion is a well-known prob...\n",
      "Text 2: ['a visualizao de relatrios de meios complement...\n",
      "Gold score: 0.1000, Predicted: 0.1504\n",
      "--------------------------------------------------------------------------------\n",
      "Text 1: ['on a business context, it is responsibility of t...\n",
      "Text 2: ['the reconstruction of genomic-scale metabolic mo...\n",
      "Gold score: 0.0000, Predicted: 0.0415\n",
      "--------------------------------------------------------------------------------\n",
      "Text 1: ['o koha  um software com interface web para gest...\n",
      "Text 2: ['devido  elevada proliferao tecnolgica, exist...\n",
      "Gold score: 0.3000, Predicted: 0.1817\n",
      "--------------------------------------------------------------------------------\n",
      "Text 1: ['real-time monitoring has become one of the most ...\n",
      "Text 2: ['a sade constitui um direito inegvel dos cidad...\n",
      "Gold score: 0.0000, Predicted: 0.0970\n",
      "--------------------------------------------------------------------------------\n",
      "Text 1: ['ao longo dos ltimos anos, tem-se assistido a um...\n",
      "Text 2: ['a deteo de danos na estrutura externa de vecu...\n",
      "Gold score: 0.0667, Predicted: -0.0412\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "\n",
    "# Load the best model (if available)\n",
    "try:\n",
    "    best_model_path = os.path.join(output_dir)\n",
    "    if os.path.exists(best_model_path):\n",
    "        model = SentenceTransformer(best_model_path)\n",
    "        print(f\"Loaded best model from {best_model_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not load best model. Using current model. Error: {e}\")\n",
    "\n",
    "# Evaluation on validation set\n",
    "print(\"Evaluating model on validation set...\")\n",
    "\n",
    "# Get embeddings for validation texts\n",
    "sentences1 = [ex.texts[0] for ex in val_examples]\n",
    "sentences2 = [ex.texts[1] for ex in val_examples]\n",
    "gold_scores = [ex.label for ex in val_examples]\n",
    "\n",
    "# Get embeddings and calculate cosine similarities\n",
    "embeddings1 = model.encode(sentences1, convert_to_tensor=True)\n",
    "embeddings2 = model.encode(sentences2, convert_to_tensor=True)\n",
    "\n",
    "cosine_scores = []\n",
    "for i in range(len(embeddings1)):\n",
    "    cosine_score = torch.nn.functional.cosine_similarity(embeddings1[i].unsqueeze(0), \n",
    "                                                        embeddings2[i].unsqueeze(0)).item()\n",
    "    cosine_scores.append(cosine_score)\n",
    "\n",
    "# Calculate correlation metrics\n",
    "pearson_corr, pearson_p = pearsonr(gold_scores, cosine_scores)\n",
    "spearman_corr, spearman_p = spearmanr(gold_scores, cosine_scores)\n",
    "\n",
    "print(f\"Pearson correlation: {pearson_corr:.4f} (p={pearson_p:.4f})\")\n",
    "print(f\"Spearman correlation: {spearman_corr:.4f} (p={spearman_p:.4f})\")\n",
    "\n",
    "# Sample predictions\n",
    "print(\"\\nSample predictions:\")\n",
    "for i in range(min(5, len(val_examples))):\n",
    "    print(f\"Text 1: {sentences1[i][:50]}...\")\n",
    "    print(f\"Text 2: {sentences2[i][:50]}...\")\n",
    "    print(f\"Gold score: {gold_scores[i]:.4f}, Predicted: {cosine_scores[i]:.4f}\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "# Save evaluation metrics\n",
    "evaluation_results = {\n",
    "    \"pearson_correlation\": pearson_corr,\n",
    "    \"spearman_correlation\": spearman_corr,\n",
    "    \"num_validation_examples\": len(val_examples)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e455bf3",
   "metadata": {},
   "source": [
    "## Information Retrieval Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718b88e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(query, documents, top_k=5, model=model):\n",
    "    try:\n",
    "        if not documents:\n",
    "            print(\"Warning: Empty document list provided\")\n",
    "            return []\n",
    "            \n",
    "        query_embedding = model.encode(query, convert_to_tensor=True, show_progress_bar=False)\n",
    "        \n",
    "        # Get document abstracts\n",
    "        doc_abstracts = []\n",
    "        for doc in documents:\n",
    "            abstract = doc.get('dc.description.abstract', '')\n",
    "            # Skip empty abstracts\n",
    "            if abstract:\n",
    "                doc_abstracts.append(abstract)\n",
    "            \n",
    "        # Encode all documents\n",
    "        doc_embeddings = model.encode(doc_abstracts, \n",
    "                                     convert_to_tensor=True, \n",
    "                                     show_progress_bar=(len(doc_abstracts) > 10))\n",
    "        \n",
    "        # Calculate similarities\n",
    "        import torch.nn.functional as F\n",
    "        similarities = F.cosine_similarity(query_embedding.unsqueeze(0), doc_embeddings)\n",
    "        \n",
    "        # Sort by similarity\n",
    "        results = []\n",
    "        for i, sim in enumerate(similarities):\n",
    "            # Find the original document that corresponds to this abstract\n",
    "            for j, doc in enumerate(documents):\n",
    "                if doc.get('dc.description.abstract', '') == doc_abstracts[i]:\n",
    "                    results.append((doc, sim.item()))\n",
    "                    break\n",
    "        \n",
    "        # Return top k results\n",
    "        return sorted(results, key=lambda x: x[1], reverse=True)[:top_k]\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error in retrieve function: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11ceac0",
   "metadata": {},
   "source": [
    "## Testing the Information Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205719ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1000 documents\n"
     ]
    }
   ],
   "source": [
    "# Load document collection\n",
    "collection_file = data_dir / \"col_1822_21316_processed.json\"\n",
    "\n",
    "try:\n",
    "    with open(collection_file, 'r', encoding='utf-8') as f:\n",
    "        documents = json.load(f)\n",
    "    print(f\"Loaded {len(documents)} documents\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error loading document collection: {e}\")\n",
    "    print(\"Creating empty document list\")\n",
    "    documents = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5873c585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Query: 'processamento de linguagem natural'\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|| 32/32 [00:08<00:00,  3.79it/s]\n",
      "Batches: 100%|| 32/32 [00:08<00:00,  3.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 results:\n",
      "\n",
      "Document 1 - Similarity: 0.5115\n",
      "Title: unfuzzying fuzzy parsing\n",
      "Authors: carvalho, pedro miguel de jesus ventura\n",
      "Abstract: ['recognizing sentences of a language in an efficient and precise manner has always been a strong subject within computer science. many theories, algorithms and techniques have been proposed along computing history, but at the end it all comes down to performing lexical and syntactic analysis of the source, originating a parse tree as the result. sometimes there is no need for full precision or even a full parse tree. a good example of one of these cases is architecture extraction from source code. in this case only a small portion of the code is of interest. another good example is recognizing handwritten expressions, because it is entirely impossible to predict the kind of calligraphy that will be analyzed, it is also impossible to perform an one hundred percent precise recognition. this need for tolerant parsing lead to the development of many forms of tolerant parsing along the years. this master work will focus on one form of tolerant parsing in particular, fuzzy parsing. from this work it is expected the emergence of a new fuzzy parsing technique based on automata, where automata states would represent context and edges would represent potential matches inside that context. the hypothesis of this work is that such an approach reduces uncertainty and recognition time. it is also expected the creation of a tool suit that facilitates the process of developing fuzzy parsers. we believe that such a tool will be a great addition to areas such as program comprehension or ide construction.', 'reconhecer frases de uma linguagem, de uma forma eficiente e precisa, tem sido sempre um tpico de interesse dentro da informtica. diversas teorias, algoritmos e tcnicas foram propostas ao longo dos anos, mas no fim de contas tudo se baseia em anlises lxicas, sintticas e semnticas da fonte, originando uma rvore de parsing como resultado. por vezes no h necessidade de um reconhecimento cem por cento preciso, nem de uma rvore de parsing completa. um bom exemplo de um desses casos, pode ser encontrado na extrao de modelos arquiteturais a partir de cdigo fonte. neste caso, apenas uma parte reduzida do cdigo tem interesse. outro bom exemplo pode ser encontrado no reconhecimento de expresses matemticas escritas manualmente. uma vez que  impossvel prever o tipo de caligrafia a ser analisada,  tambm impossvel realizar um reconhecimento cem por cento preciso. esta necessidade por tolerncia no reconhecimento levou ao desenvolvimento de vrias tcnicas de parsing tolerante ao longo dos anos. esta dissertao ir focar-se particularmente numa forma de parsing tolerante, fuzzy parsing. deste trabalho  esperado que surja uma nova tcnica de fuzzy parsing baseada em autmatos, onde os estados representaro contexto e os arcos representaro possveis correspondncias dentro desse contexto. espera-se que esta abordagem reduza a incerteza e o tempo de reconhecimento.  tambm esperado que seja criada uma ferramenta que facilite o processo de criao de outros fuzzy parsers. pensamos que uma ferramenta do gnero ser uma bela adio ao para reas como anlise de programas e construo de ambientes de desenvolvimento de software.']\n",
      "Keywords: ['fuzzy parsing', 'ide construction', 'program comprehension', 'automata', 'grammars']\n",
      "\n",
      "Document 2 - Similarity: 0.4312\n",
      "Title: avaliao automtica de testes de ateno e acuidade visual\n",
      "Authors: pereira, mariana de oliveira\n",
      "Abstract: ['in recent years, our research group on language processing, gepl, has been collaborating with centro neurosensorial de braga, led by dr. ana paula azevedo. in this context, some serious games were developed and installed for recognizing shapes, emotions and training central and peripheral vision. they are used in memory therapy, deconcentration, dyslexia, and other problems that affect the acquisition of knowledge in learning processes.the ideas that rose up along the literature review done on those areas, will be exposed along the state-of-the-art chapter in this report. this thesis proposes a system that will implement an error detection algorithm based on speech-to-text analysis to check whether the spoken sequence contains errors or not. as the system is intended to be installed in the neurosensory center, the results will be presented visually to help the therapist in their day-to-day work and monitor the actual use of the system.', 'nos ltimos anos, o nosso grupo de investigao em processamento de linguagens, gepl, tem vindo a colaborar com o centro neurossensorial de braga, liderado pela dr ana paula azevedo. neste contexto, foram desenvolvidos e instalados alguns jogos srios para reconhecimento de formas e de emoes e para treino da viso central e perifrica. estes so usados na terapia da memria, desconcentrao, dislexia e outras perturbaoes que afetam a aquisio de conhecimentos em processos de aprendizagem. as ideias que surgiram, no decorrer da reviso, de literatura feita sobre essas reas sero expostas ao longo do captulo de estado da arte deste relatrio. esta tese prope um sistema que implementar um algoritmo de deteo de erros baseado na anlise de fala para texto de modo verificar se a sequncia falada contm erros ou no. como o sistema se destina a ser instalado no centro neurossensorial, os resultados sero apresentados visualmente para auxiliar o terapeuta no seu dia-a-dia e monitorar o real uso do sistema.']\n",
      "Keywords: ['serious games', 'speech recognition', 'jogos srios', 'reconhecimento de fala']\n",
      "\n",
      "Document 3 - Similarity: 0.4085\n",
      "Title: contributions for building a corpora-flow system\n",
      "Authors: santos, andr fernandes\n",
      "Abstract: ['os corpora textuais so um recurso importante no processamento de linguagem natural e em reas relacionadas, tais como a minerao de textos biomdicos, a lingustica de corpus, aprendizagem mquina e recuperao de informao. a preparao de documentos para incluso num corpus envolve vrios passos distintos e uma rede complexa de dependncias e condies, que resulta num fluxo difcil de gerir manualmente. esta dissertao foca-se nos diversos desafios encontrados no processo de construo de corpora, e prope mtodos para ultrapassar essas questes. o primeiro problema abordado foi a limpeza de documentos de texto remoo de resduos estruturais, normalizao de formatos e notaes e deteo de delimitadores de seco tornando os documentos passveis de serem processados. outra questo abordada foi a deteo de documentos duplicados e de pares de documentos candidatos a alinhamento, tendo sido introduzido e implementado um mtodo para medio da similaridade entre documentos. posteriormente, introduziu-se o conceito de sincronizao de documentos, seguido da descrio de uma implementao baseada nos delimitadores de seco. dois casos de estudo reais foram utilizados para guiar a implementao das ferramentas desenvolvidas: alinhamento multi-lngua de documentos para incluso em corpora paralelos alinhados e a construo de corpora de textos biomdicos para minerao de texto. um prottipo de um sistema de gesto da construo de corpora foi desenvolvido  um sistema de corpora-flow. este sistema incorpora mecanismos que facilitam a implementao do fluxo necessrio para a construo de um corpus. uma avaliao comparativa do conjunto de ferramentas desenvolvido foi realizada atravs do alinhamento de documentos com e sem a interveno das ferramentas desenvolvidas. um pequeno conjunto de ferramentas foi desenvolvido para avaliar os resultados de alinhamentos.', 'text corpora are important resources on natural language processing and related areas such as biomedical text mining, corpus linguistics, machine learning and information extraction. preparing documents to be included in a corpus involves several different steps and a complex network of dependencies and conditions, which results in a workflow difficult to manage manually. this dissertation focuses on different challenges which can be found when building corpora, and proposed methods to overcome such questions. cleaning of text documents  removing structural residues, normalizing encodings and notations and finding section delimiters  to make the documents suitable for further processing. another question addressed was the detection of duplicated documents and candidate document pairs for alignment. a method for measuring the similarity between documents was introduced and implemented. then, the concept of document synchronization was introduced, followed by the description of an implementation based on section delimiters. two real-world scenarios were used to guide the implementation of the tools developed: multi-language document alignment for inclusion in parallel aligned corpora and building corpora of biomedical texts for text mining. a prototype of a corpora building management system was developed  a corpora-flow system. this system includes mechanisms which facilitate the implementation of the workflow needed to build a corpus. a comparative evaluation of the set of tools developed was performed by aligning documents with and without using the tools developed. a small set of auxiliary tools was created to evaluate the results of alignments.']\n",
      "Keywords: None\n",
      "\n",
      "================================================================================\n",
      "Query: 'web performance optimization'\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|| 32/32 [00:08<00:00,  3.78it/s]\n",
      "Batches: 100%|| 32/32 [00:08<00:00,  3.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 results:\n",
      "\n",
      "Document 1 - Similarity: 0.3808\n",
      "Title: on the performance of webassembly\n",
      "Authors: macedo, joo gonalves de\n",
      "Abstract: ['the worldwide web has dramatically evolved in recent years. web pages are dynamic, expressed by pro grams written in common programming languages given rise to sophisticated web applications. thus, web browsers are almost operating systems, having to interpret/compile such programs and execute them. although javascript is widely used to express dynamic web pages, it has several shortcomings and performance inefficiencies. to overcome such limitations, major it powerhouses are developing a new portable and size/load efficient language: webassembly. in this dissertation, we conduct the first systematic study on the energy and run-time performance of webassembly and javascript on the web. we used micro-benchmarks and real applications to have more realistic results. the results show that webassembly, while still in its infancy, is starting to already outperform javascript, with much more room to grow. a statistical analysis indicates that webassembly produces significant performance differences compared to javascript. however, these differences differ between micro-benchmarks and real-world benchmarks. our results also show that webassembly improved energy efficiency by 30%, on average, and show how different webassembly behaviour is among three popular web browsers: google chrome, microsoft edge, and mozilla firefox. our findings indicate that webassembly is faster than javascript and even more energy-efficient. our benchmarking framework is also available to allow further research and replication.', 'a web evoluiu dramaticamente em todo o mundo nos ltimos anos. as pginas web so dinmicas, expressas por programas escritos em linguagens de programao comuns, dando origem a aplicativos web sofisticados. assim, os navegadores web so quase como sistemas operacionais, tendo que interpre tar/compilar tais programas e execut-los. embora o javascript seja amplamente usado para expressar pginas web dinmicas, ele tem vrias deficincias e ineficincias de desempenho. para superar tais limitaes, as principais potncias de ti esto a desenvolver uma nova linguagem porttil e eficiente em tamanho/carregamento: webassembly. nesta dissertao, conduzimos o primeiro estudo sistemtico sobre o desempenho da energia e do tempo de execuo do webassembly e javascript na web. usamos micro-benchmarks e aplicaes reais para obter resultados mais realistas. os resultados mostram que webassembly, embora ainda esteja na sua infncia, j est comea a superar o javascript, com muito mais espao para crescer. uma anlise estatstica indica que webassembly produz diferenas de desempenho significativas em relao ao javascript. no entanto, essas diferenas diferem entre micro-benchmarks e benchmarks de aplicaes reais. os nossos resultados tambm mostram que o webassembly melhorou a eficincia energtica em 30%, em mdia, e mostram como o comportamento do webassembly  diferente entre trs navegadores web populares: google chrome, microsoft edge e mozilla firefox. as nossas descobertas indicam que o webassembly  mais rpido que o javascript e ainda mais eficiente em termos de energia. a nossa benchmarking framework est disponvel para permitir pesquisas adicionais e replicao.']\n",
      "Keywords: ['energy efficiency', 'green software', 'web browsers', 'webassembly', 'eficincia energtica', 'navegadores web', 'software verde']\n",
      "\n",
      "Document 2 - Similarity: 0.3516\n",
      "Title: query optimizers based on machine learning techniques\n",
      "Authors: souto, rui pedro sousa rodrigues do\n",
      "Abstract: ['query optimizers are considered one of the most relevant and sophisticated components in a database management system. however, despite currently producing nearly optimal results, optimizers rely on statistical estimates and heuristics to reduce the search space of alternative execution plans for a single query. as a result, for more complex queries, errors may grow exponentially, often translating into sub-optimal plans resulting in less than ideal performance. recent advances in machine learning techniques have opened new opportunities for many of the existing problems related to system optimization. this document proposes a solution built on top of postgresql that learns to select the most efficient set of optimizer strategy settings for a particular query. instead of depending entirely on the optimizers estimates to compare different plans under different configurations, it relies on a greedy selection algorithm that supports several types of predictive modeling techniques, from more traditional modeling techniques to a deep learning approach. the system is evaluated experimentally with the standard tpc-h and join order ing benchmark workloads to measure the cost and benefits of adding machine learning capabilities to traditional query optimizers.', 'os otimizadores de queries so considerados um dos componentes de maior relevncia e complexidade num sistema de gesto de bases de dados. no entanto, apesar de atualmente produzirem resultados quase timos, os otimizadores dependem do uso de estimativas estatsticas e de heursticas para reduzir o espao de procura de planos de execuo alternativos para uma determinada query. como resultado, para queries mais complexas, os erros podem crescer exponencialmente, o que geralmente se traduz em planos sub-timos, resultando num desempenho inferior ao ideal. os recentes avanos nas tcnicas de aprendizagem automtica abriram novas oportunidades para muitos dos problemas existentes relacionados com otimizao de sistemas. este documento prope uma soluo construda sobre o postgresql que aprende a selecionar o conjunto mais eficiente de configuraes do otimizador para uma determinada query. em vez de depender inteiramente de estimativas do otimizador para comparar planos de configuraes diferentes, a soluo baseia-se num algoritmo de seleo greedy que suporta vrios tipos de tcnicas de modelagem preditiva, desde tcnicas mais tradicionais a uma abordagem de deep learning. o sistema  avaliado experimentalmente com os workloads tpc-h e join ordering benchmark para medir o custo e os benefcios de adicionar aprendizagem automtica a otimizadores de queries tradicionais.']\n",
      "Keywords: ['database tuning', 'machine learning', 'query optimization', 'aprendizagem automtica', 'otimizao de queries', 'tuning de base de dados']\n",
      "\n",
      "Document 3 - Similarity: 0.3304\n",
      "Title: utilizao dos templates e modelos do django para desenvolver aplicaes web de elevado desempenho\n",
      "Authors: fernandes, joo miguel gonalves\n",
      "Abstract: ['this document describes the development of high performance web applications using django framework. initially, the operation and usage mode of django are introduced, as well as several web applications latency reduction techniques. the work carried out fo cused on the design, implementation and performance optimization of a web application, which consists of an article sharing system. the development process followed the scrum methodology. during development, several technologies were explored, such as memcached, celery and varnish, which enabled the implementation of certain performance optimi zation strategies. the latency of several operations was measured, before and after the application of optimization techniques, in order to ensure that one was moving in the right direction. the optimization of the applications performance was performed at various le vels, including the transfer of content across the network and the backend services. http caching, data compression and minification tecniques, as well as static content replication using content delivery networks, were used. partial update of the applications pages on the front-end and asynchronous processing techniques were applied. the database utili zation was optimized by creating indexes and by taking advantage of a nosql solution. memory caching strategies, with distinct granularities, were implemented to store templa tes and application objects. furthermore, asynchronous task queues were used to perform some costly operations. all of the aforementioned techniques favorably contributed to the web applications latency decrease. django only supports the application of some of these techniques, because it operates on the back-end. since performance must be optimized at various levels, it was necessary to use other tools besides django.', 'este documento descreve o desenvolvimento de aplicaes web de elevado desempenho com a framework django. inicialmente, apresenta-se o funcionamento e o modo de utiliza o do django, bem como diversas tcnicas de diminuio da latncia das aplicaes web. o trabalho realizado focou-se na conceo, implementao e otimizao do desempenho de uma aplicao web, que consiste num sistema de partilha de artigos. o processo de desenvolvimento seguiu a metodologia scrum. durante o desenvolvimento foram explo radas diversas tecnologias, tais como memcached, celery e varnish, que possibilitaram a implementao de determinadas estratgias de otimizao do desempenho. realizaram-se medies da latncia de diversas operaes, antes e aps a aplicao das estratgias de oti mizao, para garantir que se caminhava no sentido correto. a otimizao do desempenho da aplicao ocorreu a vrios nveis, incluindo a transferncia do contedo pela rede e os servios de back-end. utilizaram-se tcnicas como o caching http, bem como a compresso e minificao de informao e, ainda, a replicao de contedo esttico utilizando content delivery networks. aplicaram-se tcnicas de processamento assncrono e atualizao parcial das pginas da aplicao no front-end. otimizou-se a utilizao da base de dados, criando ndices e tirando partido de uma soluo nosql. implementaram-se estratgias de caching em memria com granularidades distintas, para armazenar templates e objetos gerados pela aplicao. recorreu-se ainda a filas assncronas de tarefas para a realizao de algumas operaes custosas. todas as tcnicas mencionadas contriburam favoravelmente para a di minuio da latncia da aplicao web. o django apenas suporta a aplicao de algumas destas tcnicas, j que opera no back-end. como o desempenho deve ser otimizado a vrios nveis, foi necessrio recorrer a outras ferramentas para alm do django.']\n",
      "Keywords: None\n",
      "\n",
      "================================================================================\n",
      "Query: 'machine learning applications'\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|| 32/32 [00:08<00:00,  3.71it/s]\n",
      "Batches: 100%|| 32/32 [00:08<00:00,  3.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 results:\n",
      "\n",
      "Document 1 - Similarity: 0.5999\n",
      "Title: in-vehicle object detection with yolo algorithm\n",
      "Authors: farinha, joo simes\n",
      "Abstract: ['with the growing computational power that we have at our disposal and the ever-increasing amount of data available the field of machine learning has given rise to deep learning, a subset of machine learning algorithms that have shown extraordinary results in a variety of applications from natural language processing to computer vision. in the field of computer vision, these algorithms have greatly improved the state-of-the-art accuracy in tasks associated with object recognition such as detection. this thesis makes use of one of these algorithms, specifically the yolo algorithm, as a basis in the development of a system capable of detecting objects laying inside a car cockpit. to this end a dataset is collected for the purpose of training the yolo algorithm on this task. a comparative analysis of the detection performance of the yolov2 and yolov3 architectures is performed.several experiments are performed by modifying the yolov3 architecture to attempt to improve its accuracy. specifically tests are performed in regards to network size, and the multiple outputs present in this network. explorative experiments are done in order to test the effect that parallel network might have on detection performance. lastly tests are done to try to find an optimal learning rate and batch size for our dataset on the new architectures.', 'com o crescente poder computacional que temos  nossa disposio e o aumento da quantidade dados a que temos acesso o campo de machine learning deu origem ao deep learning um subconjunto de algoritmos de machine learning que tm demonstrado resultados extraordinrios numa variedade de aplicaes desde processamento de linguagens naturais a viso por computador. no campo de viso por computador estes algoritmos tm levado a enormes progressos na correo de sistemas de deteo de objetos. nesta tese usamos um destes algoritmos, especificament o yolo, como base para desenvolver um sistema capaz de detetar objetos dentro de um carro. dado isto um dataset  recolhido com o propsito de treinar o algoritmo yolo nesta tarefa. uma analise comparativa da correo dos algoritmos yolov2 e yolov3 e realizada. vrias tcnicas relacionadas com a modificao da arquitetura yolov3 so exploradas para otimizar o sistema para o problema especifico de deteo a bordo de veculos. especificamente testes so realizados no contexto de tamanho da rede e dos mltiplos outputs presentes nesta rede. experiencias exploratrias so realizadas de forma a testar o efeito que redes parallelas podem ter na correo dos algoritmos. por fim testes so feitos para tentar encontrar learning rates e batch sizes apropriados para o nosso dataset nas novas arquiteturas.']\n",
      "Keywords: None\n",
      "\n",
      "Document 2 - Similarity: 0.5927\n",
      "Title: automation of machine learning models benchmarking\n",
      "Authors: s, joo pedro barros\n",
      "Abstract: [\"na rea de cincia de dados, o machine learning est-se a revelar uma ferramenta essencial para resolver problemas complexos. as empresas esto a investir em equipas de cincia de dados e machine learning para desenvolver modelos que apresentem valor para os clientes. no entanto, estes modelos so uma pequena percentagem de uma pipeline de projetos de machine learning (ml) e, para entregar um produto de ml completo,  necessrio um nmero maior de componentes. devops  uma mentalidade de engenharia e um conjunto de prticas que visa unificar o processo de desenvolvimento e o processo de operaes em um software, mlops  um conceito similar a devops mas aplicado ao desenvolvimento e entrega de solues de ml. o nvel de automatizao das etapas em uma pipeline de ml define a maturidade do processo de ml, que reflete a velocidade de treino de novos modelos com novos dados ou de treino de novos modelos com diferentes implementaes. um sistema de ml  um sistema de software, desenvolvimento e atualizaes contnuas so necessrias para garantir um sistema que escale conforme as necessidades. o principal objetivo desta tese  apoiar a criao de um sistema integrado de ml com uma arquitetura que proporcione a capacidade de ser continuamente operada em um ambiente de produo. um conceito para avaliao de desempenho de algoritmos deve ser elaborado e implementado. o principal obetivo e melhorar e ace'erar o cicio de desenvolvimento de modelos de ml na empresa. para atingir este objetivo surge a necessidade de definir uma arquitetura com especificaes e a implementao de processos automatizadas num pipeline de ml existente, este processo tm como objetivo alcanar uma ferramenta de benchmark de modelos, com capacidade de analisar o desempenho do modelo, um motor de inferncia e um banco de dados para armazenar todas as mtricas computadas. um sistema baseado em ia em desenvolvimento fornece o caso de estudo para desenvolver e validar a arquitetura. os avanos atuais na rea da conduo semiautomtica introduz a necessidade de sistemas de monitoramento que podem localizar e detectar eventos especificas no veculo. os conjuntos de sensores so instalados dentro da cabine para alimentar sistemas inteligentes que visam analisar e sinalizar certos comportamentos que podem impactar a segurana e o conforto dos passageiros..\", 'in the field of data science, ml is proving to be a core feature to solve complex real-world problems. businesses are investing in data science and ml teams to develop ai based models that can deliver business value to their users. however, these models are only a small fraction of an ml project pipeline, and to deliver an end to end ml product, a greater number of components are needed. devops is an engineering mindset and a set of practices that aims to unify the development process and the operation process on software. mlops is a similar concept to devops but applicable to the development and delivery of ml based solutions. the automation of the steps in a ml pipeline defines the maturity of the ml process, reflecting the velocity of training new models given new data or training new models given new implementations. an ml system is a software system that can support development, provide continuous integration and continuous delivery apply to help guarantee that one can reliably build and operate ml systems at scale. the main objective of this thesis are to support the creation of an integrated ml system with an archi tecture that provides the ability to be continuously operated in a production-like environment. furthermore, a concept to evaluate the performance of algorithms shall be devised and implemented. the end goal is to improve and accelerate the ml development lifecycle. to achieve this goal surges the need to define an architecture alongside specifications and the implementation of several automated steps into an existing ml pipeline. to improve and accelerate model development an model engine benchmark tool is devised capable of several features, including the ability to have dashboards for model performance evaluation, an automatic inference engine, performance metrics for the model and a database to store all the computed metrics and metadata. an ai-based system under development provides the case study to develop and validate this architec ture. the current advances of semi-automated driving introduce the need for monitoring systems to scan and detect specific events in the vehicle. sensor clusters are installed inside the vehicle cabin to feed data to intelligent systems that aim to analyze and red flag certain behaviours that can potentially impact passengers safety and comfort while using the vehicle.']\n",
      "Keywords: ['engenharia software', 'aprendizagem mquina', 'cincia dados', 'devops', 'mlops', 'machine learning', 'software', 'data science', 'pipelines', 'automation']\n",
      "\n",
      "Document 3 - Similarity: 0.5915\n",
      "Title: fault tolerant decentralized deep neural networks\n",
      "Authors: padro, joo carlos faria\n",
      "Abstract: ['machine learning is trending in computer science, especially deep learning. training algorithms that follow this approach to machine learning routinely deal with vast amounts of data. processing these enormous quantities of data requires complex computation tasks that can take a long time to produce results. distributing computation efforts across multiple machines makes sense in this context, as it allows conclusive results to be available in a shorter time frame. distributing the training of a deep neural network is not a trivial procedure. various architectures have been proposed, following two different paradigms. the most common one follows a centralized approach, where a centralized entity, broadly named parameter server, synchronizes and coordinates the updates generated by a number of workers. the alternative discards the centralized unit, assuming a decentralized architecture. the synchronization between the multiple workers is assured by communication techniques that average gradients between a node and its peers. high-end clusters are the ideal environment to deploy deep learning systems. low latency between nodes assures low idle times for workers, increasing the overall system performance. these setups, however, are expensive and are only available to a limited number of entities. on the other end, there is a continuous growth of edge devices with potentially vast amounts of available computational resources. in this dissertation, we aim to implement a fault tolerant decentralized deep neural net work training framework, capable of handling the high latency and unreliability characteristic of edge networks. to manage communication between nodes, we employ decentralized algorithms capable of estimating parameters globally', 'machine learning, mais especificamente deep learning,  um campo emergente nas cincias da computao. algoritmos de treino aplicados em deep learning lidam muito frequentemente com vastas quantidades de dados. processar estas enormes quantidades de dados requer operaes computacionais complexas que demoram demasiado tempo para produzir resultados. distribuir o esforo computacional por mltiplas mquinas faz todo o sentido neste contexto e permite um aumento significativo de desempenho. distribuir o mtodo de treino de uma rede neuronal no  um processo trivial. vrias arquiteturas tm sido propostas, seguindo dois diferentes paradigmas. o mais comum segue uma abordagem centralizada, onde uma entidade central, normalmente denominada de parameter server, sincroniza e coordena todas as atualizaes produzidas pelos workers. a alternativa passa por descartar a entidade centralizada, assumindo uma arquitetura descentralizada. a sincronizao entre workers  assegurada atravs de estratgias de comunicao descentralizadas. clusters de alta performance so o ambiente ideal para a implementao de sistemas de deep learning. a baixa latncia entre nodos assegura baixos perodos de inatividade nos workers, aumentando assim o rendimento do sistema. estas instalaes, contudo, so muito custosas, estando apenas disponveis para um pequeno nmero de entidades. por outro lado, o nmero de equipamentos nas extremidades da rede, com baixo aproveitamento de poder computacional, continua a crescer, o que torna o seu uso desejvel. nesta dissertao, visamos implementar um ambiente de treino de redes neuronais descentralizado e tolerante a faltas, apto a lidar com alta latncia nas comunicaes e baixa estabilidade nos nodos, caraterstica de redes na extremidade. para coordenar a comunicao entre os nodos, empregamos algoritmos de agregao, capazes de criar uma viso geral de parmetros numa topologia.']\n",
      "Keywords: ['distributed systems', 'machine learning', 'artificial intelligence', 'fault tolerance', 'sistemas distribudos', 'inteligncia artificial', 'tolerncia a faltas']\n"
     ]
    }
   ],
   "source": [
    "queries = [\n",
    "    \"processamento de linguagem natural\",\n",
    "    \"web performance optimization\",\n",
    "    \"machine learning applications\"\n",
    "]\n",
    "\n",
    "for query in queries:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Query: '{query}'\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    try:\n",
    "        results = retrieve(query, documents, top_k=3)\n",
    "        \n",
    "        if results:\n",
    "            print(f\"Top {len(results)} results:\")\n",
    "            for i, (doc, sim) in enumerate(results, 1):\n",
    "                print(f\"\\nDocument {i} - Similarity: {sim:.4f}\")\n",
    "                print(f\"Title: {doc.get('dc.title', 'No title')}\")\n",
    "                print(f\"Authors: {doc.get('dc.contributor.author', 'Unknown')}\")\n",
    "                \n",
    "                abstract = doc.get('dc.description.abstract', 'No abstract')\n",
    "                if len(abstract) > 200:\n",
    "                    print(f\"Abstract: {abstract[:200]}...\")\n",
    "                else:\n",
    "                    print(f\"Abstract: {abstract}\")\n",
    "                    \n",
    "                print(f\"Keywords: {doc.get('dc.subject', 'None')}\")\n",
    "        else:\n",
    "            print(\"No results found for this query.\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error testing retrieval: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
