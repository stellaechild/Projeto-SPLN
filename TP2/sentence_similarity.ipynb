{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c211ab9c",
   "metadata": {},
   "source": [
    "# Fine-tuning a model for Sentence Similarity and Information Retrieval\n",
    "\n",
    "In this notebook, we will fine-tune a sentence transformer model for document similarity tasks, specifically for the RepositoriUM collection. We'll use a pre-trained model and fine-tune it on pairs of document abstracts with similarity scores.\n",
    "\n",
    "The completed system will allow us to:\n",
    "1. Process document collections from RepositoriUM\n",
    "2. Train a similarity model on document pairs\n",
    "3. Retrieve relevant documents based on a query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b235e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (3.3.2)\n",
      "Requirement already satisfied: transformers in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (4.52.4)\n",
      "Requirement already satisfied: sentence-transformers in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (4.1.0)\n",
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (1.26.0)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (4.67.1)\n",
      "Requirement already satisfied: evaluate in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (0.4.3)\n",
      "Requirement already satisfied: huggingface_hub in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (0.32.4)\n",
      "Requirement already satisfied: torch in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (2.6.0)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from datasets) (3.13.3)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from datasets) (19.0.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: requests>=2.32.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: xxhash in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\n",
      "Requirement already satisfied: aiohttp in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from datasets) (3.10.4)\n",
      "Requirement already satisfied: packaging in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from datasets) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from huggingface_hub) (4.12.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from huggingface_hub) (1.1.3)\n",
      "Requirement already satisfied: scikit-learn in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from sentence-transformers) (1.5.2)\n",
      "Requirement already satisfied: scipy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from sentence-transformers) (1.14.1)\n",
      "Requirement already satisfied: Pillow in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from sentence-transformers) (10.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch) (3.1.5)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from aiohttp->datasets) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from aiohttp->datasets) (1.18.3)\n",
      "Requirement already satisfied: idna>=2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from yarl<2.0,>=1.0->aiohttp->datasets) (3.10)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from yarl<2.0,>=1.0->aiohttp->datasets) (0.2.1)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "!pip install datasets transformers sentence-transformers pandas numpy tqdm evaluate huggingface_hub torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a490a5a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3929228c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate>=0.26.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (1.7.0)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from accelerate>=0.26.0) (1.26.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from accelerate>=0.26.0) (25.0)\n",
      "Requirement already satisfied: psutil in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from accelerate>=0.26.0) (7.0.0)\n",
      "Requirement already satisfied: pyyaml in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from accelerate>=0.26.0) (6.0.2)\n",
      "Requirement already satisfied: torch>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from accelerate>=0.26.0) (2.6.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from accelerate>=0.26.0) (0.32.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from accelerate>=0.26.0) (0.5.3)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (3.13.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (2024.12.0)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (4.12.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (1.1.3)\n",
      "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (3.1.5)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from sympy==1.13.1->torch>=2.0.0->accelerate>=0.26.0) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from jinja2->torch>=2.0.0->accelerate>=0.26.0) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->huggingface-hub>=0.21.0->accelerate>=0.26.0) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->huggingface-hub>=0.21.0->accelerate>=0.26.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->huggingface-hub>=0.21.0->accelerate>=0.26.0) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->huggingface-hub>=0.21.0->accelerate>=0.26.0) (2025.1.31)\n"
     ]
    }
   ],
   "source": [
    "# Install accelerate package for PyTorch training support\n",
    "!pip install 'accelerate>=0.26.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0ac5a838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "import sentence_transformers\n",
    "import torch\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cbe6bdfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.utils import send_example_telemetry\n",
    "\n",
    "send_example_telemetry(\"sentence_similarity_notebook\", framework=\"pytorch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c5a700",
   "metadata": {},
   "source": [
    "## Configuring the Model\n",
    "\n",
    "We'll set the parameters for our model training. For best results in sentence similarity tasks, we should use a pre-trained sentence-transformer model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "82f536d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected model: paraphrase-multilingual-MiniLM-L12-v2\n",
      "Training parameters: 4 epochs, batch size 16, learning rate 2e-05\n"
     ]
    }
   ],
   "source": [
    "# Model configuration\n",
    "model_checkpoint = \"paraphrase-multilingual-MiniLM-L12-v2\"\n",
    "batch_size = 16  # Adjust based on your GPU memory\n",
    "max_length = 512  # Maximum sequence length\n",
    "\n",
    "# Training parameters\n",
    "num_epochs = 4  # Number of training epochs (adjust as needed)\n",
    "warmup_ratio = 0.1  # Percentage of steps for warmup\n",
    "learning_rate = 2e-5  # Learning rate for training\n",
    "\n",
    "print(f\"Selected model: {model_checkpoint}\")\n",
    "print(f\"Training parameters: {num_epochs} epochs, batch size {batch_size}, learning rate {learning_rate}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01fa71fa",
   "metadata": {},
   "source": [
    "## Loading the Dataset\n",
    "\n",
    "First, we need to load the training data that was created by our `process_data.py` script.\n",
    "This data consists of pairs of document abstracts with similarity scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d392025c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 500 document pairs\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Load the training data\n",
    "data_dir = Path(\"data\")\n",
    "train_file = data_dir / \"training_data.json\"\n",
    "\n",
    "try:\n",
    "    with open(train_file, 'r', encoding='utf-8') as f:\n",
    "        training_data = json.load(f)\n",
    "\n",
    "    print(f\"Loaded {len(training_data)} document pairs\")\n",
    "    \n",
    "    # Convert to DataFrame for easier handling\n",
    "    # Make sure we handle the data consistently as lists\n",
    "    train_df = pd.DataFrame([\n",
    "        {\"abstract1\": item[0], \"abstract2\": item[1], \"similarity\": float(item[2])}\n",
    "        for item in training_data\n",
    "    ])\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error loading training data: {e}\")\n",
    "    print(\"Please run process_data.py first to create the training data, or check the file path\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcbe6dd8",
   "metadata": {},
   "source": [
    "Let's examine the distribution of similarity scores to understand our data better:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fd7dbd0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min similarity: 0.0\n",
      "Max similarity: 0.3\n",
      "Mean similarity: 0.1371096928071928\n",
      "Median similarity: 0.06666666666666667\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Check if we have enough data\n",
    "if len(train_df) > 0:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(train_df['similarity'], bins=20)\n",
    "    plt.title('Distribution of Similarity Scores')\n",
    "    plt.xlabel('Similarity Score')\n",
    "    plt.ylabel('Count')\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Min similarity: {train_df['similarity'].min()}\")\n",
    "    print(f\"Max similarity: {train_df['similarity'].max()}\")\n",
    "    print(f\"Mean similarity: {train_df['similarity'].mean()}\")\n",
    "    print(f\"Median similarity: {train_df['similarity'].median()}\")\n",
    "else:\n",
    "    print(\"Not enough data to display similarity distribution.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9d6a63",
   "metadata": {},
   "source": [
    "Now, let's prepare the data for training by splitting it into training and validation sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1ad61ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: 400 pairs\n",
      "Validation data: 100 pairs\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Check if we have enough data for a valid split\n",
    "if len(train_df) < 10:\n",
    "    print(\"Warning: Not enough data for a meaningful split. Consider generating more data.\")\n",
    "    # Create a simple split for demonstration\n",
    "    train_data = train_df.iloc[:int(len(train_df)*0.8)]\n",
    "    val_data = train_df.iloc[int(len(train_df)*0.8):]\n",
    "else:\n",
    "    # Split data into train and validation sets\n",
    "    train_data, val_data = train_test_split(train_df, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training data: {len(train_data)} pairs\")\n",
    "print(f\"Validation data: {len(val_data)} pairs\")\n",
    "\n",
    "# Check if we have a reasonable amount of training data\n",
    "if len(train_data) < 100:\n",
    "    print(\"\\nWARNING: Training with a small dataset may lead to poor model performance.\")\n",
    "    print(\"Consider collecting more data for better results.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b5d629",
   "metadata": {},
   "source": [
    "## Preparing the Model for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4d43bc49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-10 12:53:01 - Load pretrained SentenceTransformer: paraphrase-multilingual-MiniLM-L12-v2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on: cpu\n",
      "Model successfully loaded: SentenceTransformer(\n",
      "  (0): Transformer({'max_seq_length': 128, 'do_lower_case': False}) with Transformer model: BertModel \n",
      "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
      ")\n",
      "Model is on device: cpu\n",
      "Prepared 400 training examples and 100 validation examples\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, InputExample, losses\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import time\n",
    "\n",
    "# Set the device for the model\n",
    "device_str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Training on: {device_str}\")\n",
    "\n",
    "try:\n",
    "    # Load pretrained sentence-transformer model\n",
    "    model = SentenceTransformer(model_checkpoint, device=device_str)\n",
    "    print(f\"Model successfully loaded: {model}\")\n",
    "    \n",
    "    # Check model's current device\n",
    "    print(f\"Model is on device: {next(model.parameters()).device}\")\n",
    "\n",
    "    # Prepare training examples\n",
    "    train_examples = []\n",
    "    for _, row in train_data.iterrows():\n",
    "        # Convert to string if not already\n",
    "        abstract1 = str(row['abstract1']) if not isinstance(row['abstract1'], str) else row['abstract1']\n",
    "        abstract2 = str(row['abstract2']) if not isinstance(row['abstract2'], str) else row['abstract2']\n",
    "        \n",
    "        # Create input example with properly formatted texts\n",
    "        train_examples.append(InputExample(\n",
    "            texts=[abstract1, abstract2],\n",
    "            label=float(row['similarity'])\n",
    "        ))\n",
    "\n",
    "    # Prepare validation examples\n",
    "    val_examples = []\n",
    "    for _, row in val_data.iterrows():\n",
    "        # Convert to string if not already\n",
    "        abstract1 = str(row['abstract1']) if not isinstance(row['abstract1'], str) else row['abstract1']\n",
    "        abstract2 = str(row['abstract2']) if not isinstance(row['abstract2'], str) else row['abstract2']\n",
    "        \n",
    "        val_examples.append(InputExample(\n",
    "            texts=[abstract1, abstract2],\n",
    "            label=float(row['similarity'])\n",
    "        ))\n",
    "\n",
    "    # Create data loaders\n",
    "    train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "    # Create evaluator\n",
    "    evaluator = EmbeddingSimilarityEvaluator(\n",
    "        sentences1=[ex.texts[0] for ex in val_examples],\n",
    "        sentences2=[ex.texts[1] for ex in val_examples],\n",
    "        scores=[ex.label for ex in val_examples]\n",
    "    )\n",
    "    \n",
    "    print(f\"Prepared {len(train_examples)} training examples and {len(val_examples)} validation examples\")\n",
    "except Exception as e:\n",
    "    print(f\"Error preparing model: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93629c06",
   "metadata": {},
   "source": [
    "## Training the Model\n",
    "\n",
    "Now we'll train our model using the CosineSimilarityLoss which is appropriate for similarity tasks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aef7d0d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-10 12:53:05 - Save model to information_retrieval/output/repositorium-similarity-model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training for 4 epochs with 25 batches per epoch\n",
      "Warmup steps: 10\n",
      "Error during training: fp16 mixed precision requires a GPU (not 'mps').\n",
      "Partially trained model saved to: information_retrieval/output/repositorium-similarity-model\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import losses\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import logging\n",
    "\n",
    "# Enable logging to see the training progress\n",
    "logging.basicConfig(format='%(asctime)s - %(message)s',\n",
    "                    datefmt='%Y-%m-%d %H:%M:%S',\n",
    "                    level=logging.INFO)\n",
    "\n",
    "# Define loss function\n",
    "train_loss = losses.CosineSimilarityLoss(model)\n",
    "\n",
    "# Set up training parameters\n",
    "warmup_steps = int(len(train_dataloader) * num_epochs * warmup_ratio)\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "output_path = 'information_retrieval/output/repositorium-similarity-model'\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "print(f\"Starting training for {num_epochs} epochs with {len(train_dataloader)} batches per epoch\")\n",
    "print(f\"Warmup steps: {warmup_steps}\")\n",
    "\n",
    "# Track training time\n",
    "start_time = time.time()\n",
    "\n",
    "try:\n",
    "    # Train the model with progress bar and proper logging\n",
    "    model.fit(\n",
    "        train_objectives=[(train_dataloader, train_loss)],\n",
    "        evaluator=evaluator,\n",
    "        epochs=num_epochs,\n",
    "        warmup_steps=warmup_steps,\n",
    "        output_path=output_path,\n",
    "        show_progress_bar=True,\n",
    "        callback=None,\n",
    "        use_amp=True,\n",
    "        checkpoint_path=output_path,\n",
    "        checkpoint_save_steps=len(train_dataloader),  # Save checkpoint after each epoch\n",
    "        checkpoint_save_total_limit=1  # Keep only the latest checkpoint\n",
    "    )\n",
    "    \n",
    "    # Calculate and display training time\n",
    "    training_time = time.time() - start_time\n",
    "    print(f\"Training completed in {training_time:.2f} seconds ({training_time/60:.2f} minutes)\")\n",
    "    print(f\"Model saved to: {output_path}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error during training: {e}\")\n",
    "    # Try to save the model anyway\n",
    "    try:\n",
    "        model.save(output_path)\n",
    "        print(f\"Partially trained model saved to: {output_path}\")\n",
    "    except:\n",
    "        print(\"Could not save model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b1243e",
   "metadata": {},
   "source": [
    "## Evaluating the Model\n",
    "\n",
    "Let's evaluate our trained model on the validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eb885d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-10 12:53:08 - EmbeddingSimilarityEvaluator: Evaluating the model on the  dataset:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fine-tuned model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-10 12:53:13 - Cosine-Similarity :\tPearson: 0.1459\tSpearman: 0.1312\n",
      "2025-06-10 12:53:13 - Load pretrained SentenceTransformer: paraphrase-multilingual-MiniLM-L12-v2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Pearson score: 0.1459\n",
      "Validation Spearman score: 0.1312\n",
      "Loading baseline model for comparison...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-10 12:53:17 - EmbeddingSimilarityEvaluator: Evaluating the model on the  dataset:\n",
      "2025-06-10 12:53:25 - Cosine-Similarity :\tPearson: 0.1459\tSpearman: 0.1312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Pearson score: 0.1459\n",
      "Baseline Spearman score: 0.1312\n",
      "Pearson improvement: 0.0000\n",
      "Spearman improvement: 0.0000\n",
      "The fine-tuned model doesn't show improvement. Consider adjusting parameters or collecting more training data.\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model on validation set\n",
    "try:\n",
    "    print(\"Evaluating fine-tuned model...\")\n",
    "    val_score = evaluator(model)\n",
    "    print(f\"Validation Pearson score: {val_score['pearson_cosine']:.4f}\")\n",
    "    print(f\"Validation Spearman score: {val_score['spearman_cosine']:.4f}\")\n",
    "    \n",
    "    # Compare with baseline model\n",
    "    print(\"Loading baseline model for comparison...\")\n",
    "    baseline_model = SentenceTransformer(model_checkpoint, device=device_str)\n",
    "    baseline_score = evaluator(baseline_model)\n",
    "    print(f\"Baseline Pearson score: {baseline_score['pearson_cosine']:.4f}\")\n",
    "    print(f\"Baseline Spearman score: {baseline_score['spearman_cosine']:.4f}\")\n",
    "    \n",
    "    # Calculate improvement for each metric\n",
    "    pearson_improvement = val_score['pearson_cosine'] - baseline_score['pearson_cosine']\n",
    "    spearman_improvement = val_score['spearman_cosine'] - baseline_score['spearman_cosine']\n",
    "    \n",
    "    print(f\"Pearson improvement: {pearson_improvement:.4f}\")\n",
    "    print(f\"Spearman improvement: {spearman_improvement:.4f}\")\n",
    "    \n",
    "    if pearson_improvement > 0 or spearman_improvement > 0:\n",
    "        print(\"The fine-tuned model shows improvement over the baseline!\")\n",
    "    else:\n",
    "        print(\"The fine-tuned model doesn't show improvement. Consider adjusting parameters or collecting more training data.\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error during evaluation: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e455bf3",
   "metadata": {},
   "source": [
    "## Information Retrieval Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "718b88e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(query, documents, top_k=5, model=model):\n",
    "    try:\n",
    "        # Check if documents list is empty\n",
    "        if not documents:\n",
    "            print(\"Warning: Empty document list provided\")\n",
    "            return []\n",
    "            \n",
    "        # Encode query\n",
    "        query_embedding = model.encode(query, convert_to_tensor=True, show_progress_bar=False)\n",
    "        \n",
    "        # Get document abstracts, handling missing abstracts\n",
    "        doc_abstracts = []\n",
    "        for doc in documents:\n",
    "            abstract = doc.get('dc.description.abstract', '')\n",
    "            # Skip empty abstracts\n",
    "            if abstract:\n",
    "                doc_abstracts.append(abstract)\n",
    "            \n",
    "        # Skip processing if no valid abstracts\n",
    "        if not doc_abstracts:\n",
    "            print(\"Warning: No valid abstracts found in the documents\")\n",
    "            return []\n",
    "            \n",
    "        # Encode all documents\n",
    "        doc_embeddings = model.encode(doc_abstracts, \n",
    "                                     convert_to_tensor=True, \n",
    "                                     show_progress_bar=(len(doc_abstracts) > 10))\n",
    "        \n",
    "        # Calculate similarities\n",
    "        import torch.nn.functional as F\n",
    "        similarities = F.cosine_similarity(query_embedding.unsqueeze(0), doc_embeddings)\n",
    "        \n",
    "        # Sort by similarity\n",
    "        results = []\n",
    "        for i, sim in enumerate(similarities):\n",
    "            # Find the original document that corresponds to this abstract\n",
    "            for j, doc in enumerate(documents):\n",
    "                if doc.get('dc.description.abstract', '') == doc_abstracts[i]:\n",
    "                    results.append((doc, sim.item()))\n",
    "                    break\n",
    "        \n",
    "        # Return top k results\n",
    "        return sorted(results, key=lambda x: x[1], reverse=True)[:top_k]\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error in retrieve function: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11ceac0",
   "metadata": {},
   "source": [
    "## Testing the Information Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "205719ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1000 documents\n"
     ]
    }
   ],
   "source": [
    "# Load document collection\n",
    "collection_file = data_dir / \"col_1822_21316_processed.json\"\n",
    "\n",
    "try:\n",
    "    with open(collection_file, 'r', encoding='utf-8') as f:\n",
    "        documents = json.load(f)\n",
    "    print(f\"Loaded {len(documents)} documents\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error loading document collection: {e}\")\n",
    "    print(\"Creating empty document list\")\n",
    "    documents = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5873c585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Query: 'processamento de linguagem natural em português'\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 32/32 [00:34<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 results:\n",
      "\n",
      "Document 1 - Similarity: 0.6127\n",
      "Title: applying attribute grammars to teach linguistic rules\n",
      "Authors: sousa, manuel gouveia carneiro de\n",
      "Abstract: ['this document presents the topic “applying attribute grammars to teach linguistic rules”, at universidade do minho in braga, portugal. this thesis is focused on using the formalisms of attribute grammars in order to create a tool to help linguistic students learn the different rules of a natural language. the system developed, named lyntax, consists in a processor for a domain specific language which intends to enable the user to specify different kinds of sentence structures, and afterwards, test various phrases against said structures. the processor validates and evaluates the input given, generating a grammar which is specific to a previously chosen sentence. lastly, using antlr, a parser is generated for that specific grammar referred above. the processor built by antlr also creates a syntax tree that is presented to the user for analysis purposes. an interface that supports the specification of the language (written in lyntax dsl) was built, also allowing the use of the processor and the generation of the specific grammar, exempting the user from knowing the details of the process. within this document, the focus will be primarly dedicated to the analysis of the system and how each block was built. different examples of the processor in action will be shown and explained.', 'este documento refere-se a uma dissertação sobre o tópico “aplicar gramáticas de atribu tos no ensino de regras de linguística”, e será concluída na universidade do minho em braga, portugal. esta dissertação pretende focar-se no uso dos formalismos das gramáticas de atributos de maneira a criar uma ferramenta que ajude os alunos de linguística a aprender as diversas regras da língua natural. o sistema desenvolvido, denominado de lyntax, consiste em um processor para uma linguagem de domínio específico cujo objetivo é o de permitir ao seu utilizador a possibili dade de especificar diversas estruturas de frases, e posteriormente, testar frases contra essas mesmas estruturas. o processador valida e avalia o input recebido, gerando uma gramática específica à frase previamente escolhida. por fim, usando uma ferramenta como o antlr, um parser é gerado para a gramática específica acima referida. o processador construído pelo antlr também gera a árvore de syntax que é apresentada ao utilizador com o intuito de ser analisada. foi também criada uma interface que suporta a especificação da linguagem, permitindo também o uso do processador e a geração da gramática específica, abstraindo assim o utilizador de quaisquer tipo de cálculos. neste documento, o focus primário será dedicado à análise do sistema e como cada bloco foi construído. diferentes exemplos de uso do processador serão apresentados e explicados.']\n",
      "Keywords: ['linguistic', 'natural language processing', 'attribute grammar', 'linguística', 'processamento de língua natural', 'gramáticas de atributo']\n",
      "\n",
      "Document 2 - Similarity: 0.5408\n",
      "Title: entity recognition in archival descriptions\n",
      "Authors: cunha, luís filipe da costa\n",
      "Abstract: ['at the moment, there is a vast amount of archival data spread across the portuguese archives, which keeps information from our ancestors’ times to the present day. most of this information was already transcribed to digital format, and the public can access it through archives’ online repositories. despite that, some of these documents are structured with many plain text fields without any annotations, making their content analyses difficult. in this thesis, we implemented several named entity recognition solutions to perform a semantic interpretation of the archival finding aids by extracting named entities like person, place, date, profession, and organization. these entities translate into crucial information about the context in which they are inserted. they can be used for several purposes with high confidence results, such as creating smart browsing tools by using entity linking and record linking techniques. in this way, the main challenge of this work was the creation of powerful ner models capable of producing high confidence results. in order to achieve high result scores, we annotated several corpora to train our machine learning algorithms in the archival domain. we also used different ml architectures such as maxent, cnns, lstms, and bert models. during the model’s validation, we created different environments to test the effect of the context proximity in the training data. finally, during the model’s training, we noticed a lack of available portuguese annotated data, limiting the potential of several nlp tasks. in this way, we developed an intelligent corpus annotator that uses one of our ner models to assist and accelerate the annotation process.', 'de momento, existe uma vasta quantidade de dados arquivísticos espalhados pelos arquivos portugueses, que guardam informações desde os tempos dos nossos antepassados até aos dias de hoje. a maior parte desta informação já foi transcrita para o formato digital e encontra-se disponível ao público através de repositórios online dos arquivos. apesar disso, alguns destes documentos estão estruturados com muitos campos de texto livre, sem quaisquer anotações, o que pode dificultar a análise do seu conteúdo. nesta tese, implementamos várias soluções de reconhecimento de entidades mencionadas, a fim de se realizar uma interpretação semântica sobre descrições arquivísticas, extraindo entidades tais como pessoa, local, data, profissão e organização. estes tipos de entidades traduzem-se em informação crucial sobre o contexto em que estão inseridas. com métricas de confiança suficientemente elevadas, estas entidades podem ser utilizadas para diversos fins, como a criação de ferramentas de navegação inteligente por meio de técnicas de entity linking e record linking. desta forma, o principal desafio deste trabalho consistiu na criação de poderosos modelos ner que fossem capazes de produzir resultados de elevada confiança. para alcançar tais resultados, anotamos vários datasets para treinar os nossos próprios algoritmos de aprendizado de máquina no contexto arquivístico. para além disso, usamos diferentes arquiteturas de ml tais como maxent, cnns, lstms e bert. durante a validação do modelo, criamos diferentes ambientes de teste de modo a testar o efeito da proximidade de contexto nos dados de treino. por fim, durante o treino dos modelos verificamos que existe pouca quantidade de dados disponíveis anotados em português, o que pode limitar o potencial de várias tarefas de nlp. desta forma, desenvolvemos um anotador de datasets inteligente que utiliza um dos nossos modelos de ner para auxiliar e acelerar o processo de anotação.']\n",
      "Keywords: ['named entity recognition', 'archival finding aids', 'machine learning', 'deep learning', 'bert', 'data annotation', 'reconhecimento de entidades mencionadas', 'descrições arquivísticas', 'anotação de dados']\n",
      "\n",
      "Document 3 - Similarity: 0.5284\n",
      "Title: avaliação automática de testes de atenção e acuidade visual\n",
      "Authors: pereira, mariana de oliveira\n",
      "Abstract: ['in recent years, our research group on language processing, gepl, has been collaborating with centro neurosensorial de braga, led by dr. ana paula azevedo. in this context, some serious games were developed and installed for recognizing shapes, emotions and training central and peripheral vision. they are used in memory therapy, deconcentration, dyslexia, and other problems that affect the acquisition of knowledge in learning processes.the ideas that rose up along the literature review done on those areas, will be exposed along the state-of-the-art chapter in this report. this thesis proposes a system that will implement an error detection algorithm based on speech-to-text analysis to check whether the spoken sequence contains errors or not. as the system is intended to be installed in the neurosensory center, the results will be presented visually to help the therapist in their day-to-day work and monitor the actual use of the system.', 'nos últimos anos, o nosso grupo de investigação em processamento de linguagens, gepl, tem vindo a colaborar com o centro neurossensorial de braga, liderado pela drª ana paula azevedo. neste contexto, foram desenvolvidos e instalados alguns jogos sérios para reconhecimento de formas e de emoções e para treino da visão central e periférica. estes são usados na terapia da memória, desconcentração, dislexia e outras perturbaçoes que afetam a aquisição de conhecimentos em processos de aprendizagem. as ideias que surgiram, no decorrer da revisão, de literatura feita sobre essas áreas serão expostas ao longo do capítulo de estado da arte deste relatório. esta tese propõe um sistema que implementará um algoritmo de deteção de erros baseado na análise de fala para texto de modo verificar se a sequência falada contém erros ou não. como o sistema se destina a ser instalado no centro neurossensorial, os resultados serão apresentados visualmente para auxiliar o terapeuta no seu dia-a-dia e monitorar o real uso do sistema.']\n",
      "Keywords: ['serious games', 'speech recognition', 'jogos sérios', 'reconhecimento de fala']\n",
      "\n",
      "================================================================================\n",
      "Query: 'web performance optimization'\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 32/32 [00:29<00:00,  1.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 results:\n",
      "\n",
      "Document 1 - Similarity: 0.5265\n",
      "Title: query optimizers based on machine learning techniques\n",
      "Authors: souto, rui pedro sousa rodrigues do\n",
      "Abstract: ['query optimizers are considered one of the most relevant and sophisticated components in a database management system. however, despite currently producing nearly optimal results, optimizers rely on statistical estimates and heuristics to reduce the search space of alternative execution plans for a single query. as a result, for more complex queries, errors may grow exponentially, often translating into sub-optimal plans resulting in less than ideal performance. recent advances in machine learning techniques have opened new opportunities for many of the existing problems related to system optimization. this document proposes a solution built on top of postgresql that learns to select the most efficient set of optimizer strategy settings for a particular query. instead of depending entirely on the optimizer’s estimates to compare different plans under different configurations, it relies on a greedy selection algorithm that supports several types of predictive modeling techniques, from more traditional modeling techniques to a deep learning approach. the system is evaluated experimentally with the standard tpc-h and join order ing benchmark workloads to measure the cost and benefits of adding machine learning capabilities to traditional query optimizers.', 'os otimizadores de queries são considerados um dos componentes de maior relevância e complexidade num sistema de gestão de bases de dados. no entanto, apesar de atualmente produzirem resultados quase ótimos, os otimizadores dependem do uso de estimativas estatísticas e de heurísticas para reduzir o espaço de procura de planos de execução alternativos para uma determinada query. como resultado, para queries mais complexas, os erros podem crescer exponencialmente, o que geralmente se traduz em planos sub-ótimos, resultando num desempenho inferior ao ideal. os recentes avanços nas técnicas de aprendizagem automática abriram novas oportunidades para muitos dos problemas existentes relacionados com otimização de sistemas. este documento propõe uma solução construída sobre o postgresql que aprende a selecionar o conjunto mais eficiente de configurações do otimizador para uma determinada query. em vez de depender inteiramente de estimativas do otimizador para comparar planos de configurações diferentes, a solução baseia-se num algoritmo de seleção greedy que suporta vários tipos de técnicas de modelagem preditiva, desde técnicas mais tradicionais a uma abordagem de deep learning. o sistema é avaliado experimentalmente com os workloads tpc-h e join ordering benchmark para medir o custo e os benefícios de adicionar aprendizagem automática a otimizadores de queries tradicionais.']\n",
      "Keywords: ['database tuning', 'machine learning', 'query optimization', 'aprendizagem automática', 'otimização de queries', 'tuning de base de dados']\n",
      "\n",
      "Document 2 - Similarity: 0.5202\n",
      "Title: utilização dos templates e modelos do django para desenvolver aplicações web de elevado desempenho\n",
      "Authors: fernandes, joão miguel gonçalves\n",
      "Abstract: ['this document describes the development of high performance web applications using django framework. initially, the operation and usage mode of django are introduced, as well as several web applications’ latency reduction techniques. the work carried out fo cused on the design, implementation and performance optimization of a web application, which consists of an article sharing system. the development process followed the scrum methodology. during development, several technologies were explored, such as memcached, celery and varnish, which enabled the implementation of certain performance optimi zation strategies. the latency of several operations was measured, before and after the application of optimization techniques, in order to ensure that one was moving in the right direction. the optimization of the application’s performance was performed at various le vels, including the transfer of content across the network and the backend services. http caching, data compression and minification tecniques, as well as static content replication using content delivery networks, were used. partial update of the application’s pages on the front-end and asynchronous processing techniques were applied. the database utili zation was optimized by creating indexes and by taking advantage of a nosql solution. memory caching strategies, with distinct granularities, were implemented to store templa tes and application objects. furthermore, asynchronous task queues were used to perform some costly operations. all of the aforementioned techniques favorably contributed to the web application’s latency decrease. django only supports the application of some of these techniques, because it operates on the back-end. since performance must be optimized at various levels, it was necessary to use other tools besides django.', 'este documento descreve o desenvolvimento de aplicações web de elevado desempenho com a framework django. inicialmente, apresenta-se o funcionamento e o modo de utiliza ção do django, bem como diversas técnicas de diminuição da latência das aplicações web. o trabalho realizado focou-se na conceção, implementação e otimização do desempenho de uma aplicação web, que consiste num sistema de partilha de artigos. o processo de desenvolvimento seguiu a metodologia scrum. durante o desenvolvimento foram explo radas diversas tecnologias, tais como memcached, celery e varnish, que possibilitaram a implementação de determinadas estratégias de otimização do desempenho. realizaram-se medições da latência de diversas operações, antes e após a aplicação das estratégias de oti mização, para garantir que se caminhava no sentido correto. a otimização do desempenho da aplicação ocorreu a vários níveis, incluindo a transferência do conteúdo pela rede e os serviços de back-end. utilizaram-se técnicas como o caching http, bem como a compressão e minificação de informação e, ainda, a replicação de conteúdo estático utilizando content delivery networks. aplicaram-se técnicas de processamento assíncrono e atualização parcial das páginas da aplicação no front-end. otimizou-se a utilização da base de dados, criando índices e tirando partido de uma solução nosql. implementaram-se estratégias de caching em memória com granularidades distintas, para armazenar templates e objetos gerados pela aplicação. recorreu-se ainda a filas assíncronas de tarefas para a realização de algumas operações custosas. todas as técnicas mencionadas contribuíram favoravelmente para a di minuição da latência da aplicação web. o django apenas suporta a aplicação de algumas destas técnicas, já que opera no back-end. como o desempenho deve ser otimizado a vários níveis, foi necessário recorrer a outras ferramentas para além do django.']\n",
      "Keywords: None\n",
      "\n",
      "Document 3 - Similarity: 0.5006\n",
      "Title: on the performance of webassembly\n",
      "Authors: macedo, joão gonçalves de\n",
      "Abstract: ['the worldwide web has dramatically evolved in recent years. web pages are dynamic, expressed by pro grams written in common programming languages given rise to sophisticated web applications. thus, web browsers are almost operating systems, having to interpret/compile such programs and execute them. although javascript is widely used to express dynamic web pages, it has several shortcomings and performance inefficiencies. to overcome such limitations, major it powerhouses are developing a new portable and size/load efficient language: webassembly. in this dissertation, we conduct the first systematic study on the energy and run-time performance of webassembly and javascript on the web. we used micro-benchmarks and real applications to have more realistic results. the results show that webassembly, while still in its infancy, is starting to already outperform javascript, with much more room to grow. a statistical analysis indicates that webassembly produces significant performance differences compared to javascript. however, these differences differ between micro-benchmarks and real-world benchmarks. our results also show that webassembly improved energy efficiency by 30%, on average, and show how different webassembly behaviour is among three popular web browsers: google chrome, microsoft edge, and mozilla firefox. our findings indicate that webassembly is faster than javascript and even more energy-efficient. our benchmarking framework is also available to allow further research and replication.', 'a web evoluiu dramaticamente em todo o mundo nos últimos anos. as páginas web são dinâmicas, expressas por programas escritos em linguagens de programação comuns, dando origem a aplicativos web sofisticados. assim, os navegadores web são quase como sistemas operacionais, tendo que interpre tar/compilar tais programas e executá-los. embora o javascript seja amplamente usado para expressar páginas web dinâmicas, ele tem várias deficiências e ineficiências de desempenho. para superar tais limitações, as principais potências de ti estão a desenvolver uma nova linguagem portátil e eficiente em tamanho/carregamento: webassembly. nesta dissertação, conduzimos o primeiro estudo sistemático sobre o desempenho da energia e do tempo de execução do webassembly e javascript na web. usamos micro-benchmarks e aplicações reais para obter resultados mais realistas. os resultados mostram que webassembly, embora ainda esteja na sua infância, já está começa a superar o javascript, com muito mais espaço para crescer. uma análise estatística indica que webassembly produz diferenças de desempenho significativas em relação ao javascript. no entanto, essas diferenças diferem entre micro-benchmarks e benchmarks de aplicações reais. os nossos resultados também mostram que o webassembly melhorou a eficiência energética em 30%, em média, e mostram como o comportamento do webassembly é diferente entre três navegadores web populares: google chrome, microsoft edge e mozilla firefox. as nossas descobertas indicam que o webassembly é mais rápido que o javascript e ainda mais eficiente em termos de energia. a nossa benchmarking framework está disponível para permitir pesquisas adicionais e replicação.']\n",
      "Keywords: ['energy efficiency', 'green software', 'web browsers', 'webassembly', 'eficiência energética', 'navegadores web', 'software verde']\n",
      "\n",
      "================================================================================\n",
      "Query: 'machine learning applications'\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 32/32 [00:31<00:00,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 results:\n",
      "\n",
      "Document 1 - Similarity: 0.6996\n",
      "Title: in-vehicle object detection with yolo algorithm\n",
      "Authors: farinha, joão simões\n",
      "Abstract: ['with the growing computational power that we have at our disposal and the ever-increasing amount of data available the field of machine learning has given rise to deep learning, a subset of machine learning algorithms that have shown extraordinary results in a variety of applications from natural language processing to computer vision. in the field of computer vision, these algorithms have greatly improved the state-of-the-art accuracy in tasks associated with object recognition such as detection. this thesis makes use of one of these algorithms, specifically the yolo algorithm, as a basis in the development of a system capable of detecting objects laying inside a car cockpit. to this end a dataset is collected for the purpose of training the yolo algorithm on this task. a comparative analysis of the detection performance of the yolov2 and yolov3 architectures is performed.several experiments are performed by modifying the yolov3 architecture to attempt to improve its accuracy. specifically tests are performed in regards to network size, and the multiple outputs present in this network. explorative experiments are done in order to test the effect that parallel network might have on detection performance. lastly tests are done to try to find an optimal learning rate and batch size for our dataset on the new architectures.', 'com o crescente poder computacional que temos à nossa disposição e o aumento da quantidade dados a que temos acesso o campo de machine learning deu origem ao deep learning um subconjunto de algoritmos de machine learning que têm demonstrado resultados extraordinários numa variedade de aplicações desde processamento de linguagens naturais a visão por computador. no campo de visão por computador estes algoritmos têm levado a enormes progressos na correção de sistemas de deteção de objetos. nesta tese usamos um destes algoritmos, especificament o yolo, como base para desenvolver um sistema capaz de detetar objetos dentro de um carro. dado isto um dataset é recolhido com o propósito de treinar o algoritmo yolo nesta tarefa. uma analise comparativa da correção dos algoritmos yolov2 e yolov3 ´e realizada. várias técnicas relacionadas com a modificação da arquitetura yolov3 são exploradas para otimizar o sistema para o problema especifico de deteção a bordo de veículos. especificamente testes são realizados no contexto de tamanho da rede e dos múltiplos outputs presentes nesta rede. experiencias exploratórias são realizadas de forma a testar o efeito que redes parallelas podem ter na correção dos algoritmos. por fim testes são feitos para tentar encontrar learning rates e batch sizes apropriados para o nosso dataset nas novas arquiteturas.']\n",
      "Keywords: None\n",
      "\n",
      "Document 2 - Similarity: 0.6607\n",
      "Title: fault tolerant decentralized deep neural networks\n",
      "Authors: padrão, joão carlos faria\n",
      "Abstract: ['machine learning is trending in computer science, especially deep learning. training algorithms that follow this approach to machine learning routinely deal with vast amounts of data. processing these enormous quantities of data requires complex computation tasks that can take a long time to produce results. distributing computation efforts across multiple machines makes sense in this context, as it allows conclusive results to be available in a shorter time frame. distributing the training of a deep neural network is not a trivial procedure. various architectures have been proposed, following two different paradigms. the most common one follows a centralized approach, where a centralized entity, broadly named parameter server, synchronizes and coordinates the updates generated by a number of workers. the alternative discards the centralized unit, assuming a decentralized architecture. the synchronization between the multiple workers is assured by communication techniques that average gradients between a node and its peers. high-end clusters are the ideal environment to deploy deep learning systems. low latency between nodes assures low idle times for workers, increasing the overall system performance. these setups, however, are expensive and are only available to a limited number of entities. on the other end, there is a continuous growth of edge devices with potentially vast amounts of available computational resources. in this dissertation, we aim to implement a fault tolerant decentralized deep neural net work training framework, capable of handling the high latency and unreliability characteristic of edge networks. to manage communication between nodes, we employ decentralized algorithms capable of estimating parameters globally', 'machine learning, mais especificamente deep learning, é um campo emergente nas ciências da computação. algoritmos de treino aplicados em deep learning lidam muito frequentemente com vastas quantidades de dados. processar estas enormes quantidades de dados requer operações computacionais complexas que demoram demasiado tempo para produzir resultados. distribuir o esforço computacional por múltiplas máquinas faz todo o sentido neste contexto e permite um aumento significativo de desempenho. distribuir o método de treino de uma rede neuronal não é um processo trivial. várias arquiteturas têm sido propostas, seguindo dois diferentes paradigmas. o mais comum segue uma abordagem centralizada, onde uma entidade central, normalmente denominada de parameter server, sincroniza e coordena todas as atualizações produzidas pelos workers. a alternativa passa por descartar a entidade centralizada, assumindo uma arquitetura descentralizada. a sincronização entre workers é assegurada através de estratégias de comunicação descentralizadas. clusters de alta performance são o ambiente ideal para a implementação de sistemas de deep learning. a baixa latência entre nodos assegura baixos períodos de inatividade nos workers, aumentando assim o rendimento do sistema. estas instalações, contudo, são muito custosas, estando apenas disponíveis para um pequeno número de entidades. por outro lado, o número de equipamentos nas extremidades da rede, com baixo aproveitamento de poder computacional, continua a crescer, o que torna o seu uso desejável. nesta dissertação, visamos implementar um ambiente de treino de redes neuronais descentralizado e tolerante a faltas, apto a lidar com alta latência nas comunicações e baixa estabilidade nos nodos, caraterística de redes na extremidade. para coordenar a comunicação entre os nodos, empregamos algoritmos de agregação, capazes de criar uma visão geral de parâmetros numa topologia.']\n",
      "Keywords: ['distributed systems', 'machine learning', 'artificial intelligence', 'fault tolerance', 'sistemas distribuídos', 'inteligência artificial', 'tolerância a faltas']\n",
      "\n",
      "Document 3 - Similarity: 0.6420\n",
      "Title: deeploy: a neural network computer vision tool (for the nvidia tegra tx2 embedded system)\n",
      "Authors: fernandes, joão pedro alves\n",
      "Abstract: ['machine learning (ml) gives a computer system the ability to perform a certain task without being explicitly programmed to do it. although ml is not a new topic in the field of computer science, these techniques have been gaining increasing popularity due to advances in hardware (especially gpus). more powerful hardware supports more efficient training and a more responsive end-system, once deployed. these algorithms have proven to be particularly effective in image processing and feature detection, namely with deep neural networks. in the context of a vehicle, autonomous or not, perceiving its external and internal environment enables the ability to detect and identify left behind objects, its misuse or other potentially dangerous situations. this captured data is relevant to trigger vehicle intelligent responses. bosch is currently developing a system that has these capabilities and plans to leverage deep learning approaches to implement it. this work aimed to test and evaluate the suitability of a given embedded device for the project. it also determined the best strategy to implement deep learning solutions in the device. the supplied test bed was a nvidia software development kit (sdk) system for the embedded nvidia jetson tx2 device with the system-on-chip (soc) parker, an heterogeneous computing chip with 2 denver-cores (a nvidia implementation of arm-64 architecture), 4 cortexa57-cores (also arm-64), 256 pascal gpu-cores and support for up to 6 video cameras. the sdk includes several software library packages, including for image processing and ml. with the goal of fully exploiting the embedded device compute capabilities, this work studied several inference frameworks, going as far as implementing an inference engine from scratch (named deeploy) that produces inferences based on two libraries provided by nvidia: cudnn and tensorrt. deeploy was evaluated against well known and established frameworks, namely tensorflow, pytorch and darknet, in terms of efficiency, resource management and overall ease of use, maintainability and flexibility. this work also exploited key performance related features available on the device, such as power modes, half-precision floating point computation and the implemented shared memory architecture between the gpu-cores and the cpu-cores.', 'machine learning dá a um sistema informático a capacidade de completar uma dada tarefa sem ser explicitamente programado para tal. apesar de machine learning não ser um tópico novo no campo da engenharia informática, estas técnicas têm-se tornado cada vez mais comuns devido a avanços no hardware (especialmente nos gpus). hardware mais computa-cionalmente capaz dá origem a treinos mais eficientes e a sistemas em campo mais rápidos. este tipo de técnicas, em especial redes neuronais, demonstraram-se eficazes no processa-mento de imagens e deteção de objetos. no contexto de um veículo, autónomo ou não, perceber o seu interior e o ambiente no qual este se insere é essencial para detetar objetos esquecidos, o uso indevido do mesmo ou outro tipo de situações perigosas. esta informação é essencial para desencadear respostas inteligentes por parte do veículo. a bosch está atualmente a desenvolver um sistema com estas capacidades e para o implementar pretende utilizar soluções baseadas em redes neu-ronais. com o projeto pretendeu-se testar e avaliar a aptidão de um dado dispositivo embe-bido para este projeto. serviu também para determinar a melhor estratégia para se fazer a implementação de redes neuronais neste dispositivo. os testes foram feitos num kit de desenvolvimento da nvidia que consiste num nvidia jetson tx2 que contém um chip de computação heterogéneo composto por 2 cores denver (implementação da nvidia da ar-quitetura arm-64), 4 cores cortexa57 (também arm-64), 256 cores gpu pascal e capacidade de se conectar até 6 camaras de vídeo. o kit de desenvolvimento inclui várias bibliotecas de software para processamento de imagem e até para ml. com o objectivo de tirar total partido das capacidades computacionais do sistema em-bebido, este trabalho explorou várias plataformas de inferência, implementando mesmo um motor de raiz capaz de fazer inferência recorrendo a duas bibliotecas desenvolvi-das pela nvidia: cudnn e tensorrt. foi também feita uma comparação entre as duas implementações desenvolvidas e frameworks tradicionais como tensorflow, pytorch e dark-net no que toca a eficiência, facilidade de manutenção e flexibilidade. este trabalho ex-plorou também as features chave que estão relacionadas com performance disponibilizadas pelo dispositivo embebido, como modos de consumo de energia, computação numérica de virgula flutuante de meia precisão e a arquitetura de memória partilhada implementada entre os múltiplos cores arm-64 e os cuda-cores do gpu.']\n",
      "Keywords: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Example query\n",
    "queries = [\n",
    "    \"processamento de linguagem natural em português\",\n",
    "    \"web performance optimization\",\n",
    "    \"machine learning applications\"\n",
    "]\n",
    "\n",
    "# Test the retrieval function with each query\n",
    "for query in queries:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Query: '{query}'\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    try:\n",
    "        # Retrieve similar documents\n",
    "        results = retrieve(query, documents, top_k=3)\n",
    "        \n",
    "        # Display results\n",
    "        if results:\n",
    "            print(f\"Top {len(results)} results:\")\n",
    "            for i, (doc, sim) in enumerate(results, 1):\n",
    "                print(f\"\\nDocument {i} - Similarity: {sim:.4f}\")\n",
    "                print(f\"Title: {doc.get('dc.title', 'No title')}\")\n",
    "                print(f\"Authors: {doc.get('dc.contributor.author', 'Unknown')}\")\n",
    "                \n",
    "                abstract = doc.get('dc.description.abstract', 'No abstract')\n",
    "                if len(abstract) > 200:\n",
    "                    print(f\"Abstract: {abstract[:200]}...\")\n",
    "                else:\n",
    "                    print(f\"Abstract: {abstract}\")\n",
    "                    \n",
    "                print(f\"Keywords: {doc.get('dc.subject', 'None')}\")\n",
    "        else:\n",
    "            print(\"No results found for this query.\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error testing retrieval: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
