{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c211ab9c",
   "metadata": {},
   "source": [
    "# Fine-tuning a model for Sentence Similarity and Information Retrieval\n",
    "\n",
    "In this notebook, we will fine-tune a sentence transformer model for document similarity tasks, specifically for the RepositoriUM collection. We'll use a pre-trained model and fine-tune it on pairs of document abstracts with similarity scores.\n",
    "\n",
    "The completed system will allow us to:\n",
    "1. Process document collections from RepositoriUM\n",
    "2. Train a similarity model on document pairs\n",
    "3. Retrieve relevant documents based on a query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b235e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /home/tomas/miniconda3/lib/python3.12/site-packages (3.6.0)\n",
      "Requirement already satisfied: transformers in /home/tomas/miniconda3/lib/python3.12/site-packages (4.52.4)\n",
      "Requirement already satisfied: sentence-transformers in /home/tomas/miniconda3/lib/python3.12/site-packages (4.1.0)\n",
      "Requirement already satisfied: pandas in /home/tomas/miniconda3/lib/python3.12/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in /home/tomas/miniconda3/lib/python3.12/site-packages (1.26.4)\n",
      "Requirement already satisfied: tqdm in /home/tomas/miniconda3/lib/python3.12/site-packages (4.66.4)\n",
      "Requirement already satisfied: evaluate in /home/tomas/miniconda3/lib/python3.12/site-packages (0.4.3)\n",
      "Requirement already satisfied: huggingface_hub in /home/tomas/miniconda3/lib/python3.12/site-packages (0.32.4)\n",
      "Requirement already satisfied: torch in /home/tomas/miniconda3/lib/python3.12/site-packages (2.6.0)\n",
      "Requirement already satisfied: accelerate>=0.26.0 in /home/tomas/miniconda3/lib/python3.12/site-packages (1.7.0)\n",
      "Requirement already satisfied: filelock in /home/tomas/miniconda3/lib/python3.12/site-packages (from datasets) (3.17.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/tomas/miniconda3/lib/python3.12/site-packages (from datasets) (20.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/tomas/miniconda3/lib/python3.12/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: requests>=2.32.2 in /home/tomas/miniconda3/lib/python3.12/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: xxhash in /home/tomas/miniconda3/lib/python3.12/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /home/tomas/miniconda3/lib/python3.12/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /home/tomas/miniconda3/lib/python3.12/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.2.0)\n",
      "Requirement already satisfied: packaging in /home/tomas/miniconda3/lib/python3.12/site-packages (from datasets) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/tomas/miniconda3/lib/python3.12/site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: filelock in /home/tomas/miniconda3/lib/python3.12/site-packages (from datasets) (3.17.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/tomas/miniconda3/lib/python3.12/site-packages (from datasets) (20.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/tomas/miniconda3/lib/python3.12/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: requests>=2.32.2 in /home/tomas/miniconda3/lib/python3.12/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: xxhash in /home/tomas/miniconda3/lib/python3.12/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /home/tomas/miniconda3/lib/python3.12/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /home/tomas/miniconda3/lib/python3.12/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.2.0)\n",
      "Requirement already satisfied: packaging in /home/tomas/miniconda3/lib/python3.12/site-packages (from datasets) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/tomas/miniconda3/lib/python3.12/site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/tomas/miniconda3/lib/python3.12/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/tomas/miniconda3/lib/python3.12/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/tomas/miniconda3/lib/python3.12/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: scikit-learn in /home/tomas/miniconda3/lib/python3.12/site-packages (from sentence-transformers) (1.5.2)\n",
      "Requirement already satisfied: scipy in /home/tomas/miniconda3/lib/python3.12/site-packages (from sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: Pillow in /home/tomas/miniconda3/lib/python3.12/site-packages (from sentence-transformers) (11.1.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /home/tomas/miniconda3/lib/python3.12/site-packages (from sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/tomas/miniconda3/lib/python3.12/site-packages (from pandas) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/tomas/miniconda3/lib/python3.12/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/tomas/miniconda3/lib/python3.12/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/tomas/miniconda3/lib/python3.12/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/tomas/miniconda3/lib/python3.12/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/tomas/miniconda3/lib/python3.12/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: scikit-learn in /home/tomas/miniconda3/lib/python3.12/site-packages (from sentence-transformers) (1.5.2)\n",
      "Requirement already satisfied: scipy in /home/tomas/miniconda3/lib/python3.12/site-packages (from sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: Pillow in /home/tomas/miniconda3/lib/python3.12/site-packages (from sentence-transformers) (11.1.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /home/tomas/miniconda3/lib/python3.12/site-packages (from sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/tomas/miniconda3/lib/python3.12/site-packages (from pandas) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/tomas/miniconda3/lib/python3.12/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/tomas/miniconda3/lib/python3.12/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /home/tomas/miniconda3/lib/python3.12/site-packages (from huggingface_hub) (1.1.3)\n",
      "Requirement already satisfied: networkx in /home/tomas/miniconda3/lib/python3.12/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/tomas/miniconda3/lib/python3.12/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/tomas/miniconda3/lib/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/tomas/miniconda3/lib/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/tomas/miniconda3/lib/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/tomas/miniconda3/lib/python3.12/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/tomas/miniconda3/lib/python3.12/site-packages (from torch) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/tomas/miniconda3/lib/python3.12/site-packages (from torch) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/tomas/miniconda3/lib/python3.12/site-packages (from torch) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/tomas/miniconda3/lib/python3.12/site-packages (from torch) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/tomas/miniconda3/lib/python3.12/site-packages (from torch) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /home/tomas/miniconda3/lib/python3.12/site-packages (from torch) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/tomas/miniconda3/lib/python3.12/site-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/tomas/miniconda3/lib/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/tomas/miniconda3/lib/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /home/tomas/miniconda3/lib/python3.12/site-packages (from torch) (3.2.0)\n",
      "Requirement already satisfied: setuptools in /home/tomas/.local/lib/python3.12/site-packages (from torch) (75.8.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/tomas/miniconda3/lib/python3.12/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /home/tomas/miniconda3/lib/python3.12/site-packages (from huggingface_hub) (1.1.3)\n",
      "Requirement already satisfied: networkx in /home/tomas/miniconda3/lib/python3.12/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/tomas/miniconda3/lib/python3.12/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/tomas/miniconda3/lib/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/tomas/miniconda3/lib/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/tomas/miniconda3/lib/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/tomas/miniconda3/lib/python3.12/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/tomas/miniconda3/lib/python3.12/site-packages (from torch) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/tomas/miniconda3/lib/python3.12/site-packages (from torch) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/tomas/miniconda3/lib/python3.12/site-packages (from torch) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/tomas/miniconda3/lib/python3.12/site-packages (from torch) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/tomas/miniconda3/lib/python3.12/site-packages (from torch) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /home/tomas/miniconda3/lib/python3.12/site-packages (from torch) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/tomas/miniconda3/lib/python3.12/site-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/tomas/miniconda3/lib/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/tomas/miniconda3/lib/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /home/tomas/miniconda3/lib/python3.12/site-packages (from torch) (3.2.0)\n",
      "Requirement already satisfied: setuptools in /home/tomas/.local/lib/python3.12/site-packages (from torch) (75.8.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/tomas/miniconda3/lib/python3.12/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/tomas/miniconda3/lib/python3.12/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: psutil in /home/tomas/miniconda3/lib/python3.12/site-packages (from accelerate>=0.26.0) (6.0.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/tomas/miniconda3/lib/python3.12/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: psutil in /home/tomas/miniconda3/lib/python3.12/site-packages (from accelerate>=0.26.0) (6.0.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/tomas/miniconda3/lib/python3.12/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.9)\n",
      "Requirement already satisfied: six>=1.5 in /home/tomas/miniconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/tomas/miniconda3/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/tomas/miniconda3/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/tomas/miniconda3/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/tomas/miniconda3/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/tomas/miniconda3/lib/python3.12/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.9)\n",
      "Requirement already satisfied: six>=1.5 in /home/tomas/miniconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/tomas/miniconda3/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/tomas/miniconda3/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/tomas/miniconda3/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/tomas/miniconda3/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/tomas/miniconda3/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/tomas/miniconda3/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/tomas/miniconda3/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/tomas/miniconda3/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/tomas/miniconda3/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/tomas/miniconda3/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /home/tomas/miniconda3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/tomas/miniconda3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/tomas/miniconda3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/tomas/miniconda3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.6.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/tomas/miniconda3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/tomas/miniconda3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/tomas/miniconda3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /home/tomas/miniconda3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/tomas/miniconda3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/tomas/miniconda3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/tomas/miniconda3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.6.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/tomas/miniconda3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/tomas/miniconda3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/tomas/miniconda3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "!pip install datasets transformers sentence-transformers pandas numpy tqdm evaluate huggingface_hub torch 'accelerate>=0.26.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac5a838",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tomas/miniconda3/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "import sentence_transformers\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbe6bdfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.utils import send_example_telemetry\n",
    "\n",
    "send_example_telemetry(\"sentence_similarity_notebook\", framework=\"pytorch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c5a700",
   "metadata": {},
   "source": [
    "## Configuring the Model\n",
    "\n",
    "We'll set the parameters for our model training. For best results in sentence similarity tasks, we should use a pre-trained sentence-transformer model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f536d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model configuration\n",
    "model_checkpoint = \"paraphrase-multilingual-MiniLM-L12-v2\"\n",
    "batch_size = 16\n",
    "max_length = 512\n",
    "\n",
    "# Training parameters\n",
    "num_epochs = 3\n",
    "warmup_ratio = 0.1\n",
    "learning_rate = 2e-5\n",
    "weight_decay = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01fa71fa",
   "metadata": {},
   "source": [
    "## Loading the Dataset\n",
    "\n",
    "First, we need to load the training data that was created by our `process_data.py` script.\n",
    "This data consists of pairs of document abstracts with similarity scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d392025c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 500 document pairs\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "data_dir = Path(\"data\")\n",
    "train_file = data_dir / \"training_data.json\"\n",
    "\n",
    "try:\n",
    "    with open(train_file, 'r', encoding='utf-8') as f:\n",
    "        training_data = json.load(f)\n",
    "\n",
    "    print(f\"Loaded {len(training_data)} document pairs\")\n",
    "    \n",
    "    train_df = pd.DataFrame([\n",
    "        {\"abstract1\": item[0], \"abstract2\": item[1], \"similarity\": float(item[2])}\n",
    "        for item in training_data\n",
    "    ])\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error loading training data: {e}\")\n",
    "    print(\"Please run process_data.py first to create the training data, or check the file path\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcbe6dd8",
   "metadata": {},
   "source": [
    "Let's examine the distribution of similarity scores to understand our data better:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd7dbd0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min similarity: 0.0\n",
      "Max similarity: 0.3\n",
      "Mean similarity: 0.1371096928071928\n",
      "Median similarity: 0.06666666666666667\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if len(train_df) > 0:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(train_df['similarity'], bins=20)\n",
    "    plt.title('Distribution of Similarity Scores')\n",
    "    plt.xlabel('Similarity Score')\n",
    "    plt.ylabel('Count')\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Min similarity: {train_df['similarity'].min()}\")\n",
    "    print(f\"Max similarity: {train_df['similarity'].max()}\")\n",
    "    print(f\"Mean similarity: {train_df['similarity'].mean()}\")\n",
    "    print(f\"Median similarity: {train_df['similarity'].median()}\")\n",
    "else:\n",
    "    print(\"Not enough data to display similarity distribution.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9d6a63",
   "metadata": {},
   "source": [
    "Now, let's prepare the data for training by splitting it into training and validation sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ad61ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: 400 pairs\n",
      "Validation data: 100 pairs\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "if len(train_df) < 10:\n",
    "    print(\"Warning: Not enough data for a meaningful split. Consider generating more data.\")\n",
    "    # Create a simple split for demonstration\n",
    "    train_data = train_df.iloc[:int(len(train_df)*0.8)]\n",
    "    val_data = train_df.iloc[int(len(train_df)*0.8):]\n",
    "else:\n",
    "    # Split data into train and validation sets\n",
    "    train_data, val_data = train_test_split(train_df, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training data: {len(train_data)} pairs\")\n",
    "print(f\"Validation data: {len(val_data)} pairs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b5d629",
   "metadata": {},
   "source": [
    "## Preparing the Model for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d43bc49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model successfully loaded: SentenceTransformer(\n",
      "  (0): Transformer({'max_seq_length': 128, 'do_lower_case': False}) with Transformer model: BertModel \n",
      "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
      ")\n",
      "Model is on device: cuda:0\n",
      "Prepared 400 training examples and 100 validation examples\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, InputExample, losses\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import time\n",
    "\n",
    "device_str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "try:\n",
    "    model = SentenceTransformer(model_checkpoint, device=device_str)\n",
    "    print(f\"Model successfully loaded: {model}\")\n",
    "    \n",
    "    print(f\"Model is on device: {next(model.parameters()).device}\")\n",
    "\n",
    "    train_examples = []\n",
    "    for _, row in train_data.iterrows():\n",
    "        abstract1 = str(row['abstract1']) if not isinstance(row['abstract1'], str) else row['abstract1']\n",
    "        abstract2 = str(row['abstract2']) if not isinstance(row['abstract2'], str) else row['abstract2']\n",
    "        \n",
    "        train_examples.append(InputExample(\n",
    "            texts=[abstract1, abstract2],\n",
    "            label=float(row['similarity'])\n",
    "        ))\n",
    "\n",
    "    val_examples = []\n",
    "    for _, row in val_data.iterrows():\n",
    "        abstract1 = str(row['abstract1']) if not isinstance(row['abstract1'], str) else row['abstract1']\n",
    "        abstract2 = str(row['abstract2']) if not isinstance(row['abstract2'], str) else row['abstract2']\n",
    "        \n",
    "        val_examples.append(InputExample(\n",
    "            texts=[abstract1, abstract2],\n",
    "            label=float(row['similarity'])\n",
    "        ))\n",
    "\n",
    "    # Define a custom collate function for InputExample objects\n",
    "    def collate_fn(batch):\n",
    "        texts = [example.texts for example in batch]\n",
    "        labels = [example.label for example in batch]\n",
    "        return {\"texts\": texts, \"labels\": torch.tensor(labels)}\n",
    "\n",
    "    # Create DataLoader for training with the custom collate function\n",
    "    train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=batch_size, collate_fn=collate_fn)\n",
    "\n",
    "    evaluator = EmbeddingSimilarityEvaluator(\n",
    "        sentences1=[ex.texts[0] for ex in val_examples],\n",
    "        sentences2=[ex.texts[1] for ex in val_examples],\n",
    "        scores=[ex.label for ex in val_examples]\n",
    "    )\n",
    "    \n",
    "    print(f\"Prepared {len(train_examples)} training examples and {len(val_examples)} validation examples\")\n",
    "except Exception as e:\n",
    "    print(f\"Error preparing model: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c834f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model successfully loaded: SentenceTransformer(\n",
      "  (0): Transformer({'max_seq_length': 128, 'do_lower_case': False}) with Transformer model: BertModel \n",
      "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
      ")\n",
      "Model is on device: cuda:0\n",
      "Prepared 400 training examples and 100 validation examples\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, InputExample, losses\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import time\n",
    "\n",
    "device_str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "try:\n",
    "    model = SentenceTransformer(model_checkpoint, device=device_str)\n",
    "    print(f\"Model successfully loaded: {model}\")\n",
    "    \n",
    "    print(f\"Model is on device: {next(model.parameters()).device}\")\n",
    "\n",
    "    train_examples = []\n",
    "    for _, row in train_data.iterrows():\n",
    "        abstract1 = str(row['abstract1']) if not isinstance(row['abstract1'], str) else row['abstract1']\n",
    "        abstract2 = str(row['abstract2']) if not isinstance(row['abstract2'], str) else row['abstract2']\n",
    "        \n",
    "        train_examples.append(InputExample(\n",
    "            texts=[abstract1, abstract2],\n",
    "            label=float(row['similarity'])\n",
    "        ))\n",
    "\n",
    "    val_examples = []\n",
    "    for _, row in val_data.iterrows():\n",
    "        abstract1 = str(row['abstract1']) if not isinstance(row['abstract1'], str) else row['abstract1']\n",
    "        abstract2 = str(row['abstract2']) if not isinstance(row['abstract2'], str) else row['abstract2']\n",
    "        \n",
    "        val_examples.append(InputExample(\n",
    "            texts=[abstract1, abstract2],\n",
    "            label=float(row['similarity'])\n",
    "        ))\n",
    "\n",
    "    # Define a custom collate function for InputExample objects\n",
    "    def collate_fn(batch):\n",
    "        texts = [example.texts for example in batch]\n",
    "        labels = [example.label for example in batch]\n",
    "        return {\"texts\": texts, \"labels\": torch.tensor(labels)}\n",
    "\n",
    "    # Create DataLoader for training with the custom collate function\n",
    "    train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=batch_size, collate_fn=collate_fn)\n",
    "\n",
    "    evaluator = EmbeddingSimilarityEvaluator(\n",
    "        sentences1=[ex.texts[0] for ex in val_examples],\n",
    "        sentences2=[ex.texts[1] for ex in val_examples],\n",
    "        scores=[ex.label for ex in val_examples]\n",
    "    )\n",
    "    \n",
    "    print(f\"Prepared {len(train_examples)} training examples and {len(val_examples)} validation examples\")\n",
    "except Exception as e:\n",
    "    print(f\"Error preparing model: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93629c06",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82d367c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training at 2025-06-16 15:21:43.036442\n",
      "Total steps: 75, Warmup steps: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='75' max='75' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [75/75 01:19, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Pearson Cosine</th>\n",
       "      <th>Spearman Cosine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.134526</td>\n",
       "      <td>0.143764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.149253</td>\n",
       "      <td>0.150622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.149505</td>\n",
       "      <td>0.156179</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed. Model saved to information_retrieval/output/repositorium-similarity-model\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import losses\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Create an output directory for saving the model\n",
    "output_dir = os.path.join(\"information_retrieval/output\", \"repositorium-similarity-model\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Calculate number of warmup steps\n",
    "num_training_steps = len(train_dataloader) * num_epochs\n",
    "warmup_steps = int(num_training_steps * warmup_ratio)\n",
    "\n",
    "# Define loss function (CosineSimilarityLoss for regression of similarity scores)\n",
    "train_loss = losses.CosineSimilarityLoss(model=model)\n",
    "\n",
    "# Start training\n",
    "print(f\"Starting training at {datetime.now()}\")\n",
    "print(f\"Total steps: {num_training_steps}, Warmup steps: {warmup_steps}\")\n",
    "\n",
    "try:\n",
    "    model.fit(\n",
    "        train_objectives=[(train_dataloader, train_loss)],\n",
    "        evaluator=evaluator,\n",
    "        epochs=num_epochs,\n",
    "        warmup_steps=warmup_steps,\n",
    "        weight_decay=weight_decay, \n",
    "        output_path=output_dir,\n",
    "        optimizer_params={'lr': learning_rate},\n",
    "        show_progress_bar=True,\n",
    "        evaluation_steps=25,\n",
    "        save_best_model=True\n",
    "    )\n",
    "    \n",
    "    print(f\"Training completed. Model saved to {output_dir}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error during training: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1dbdf07",
   "metadata": {},
   "source": [
    "## Evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8cdd837c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded best model from information_retrieval/output/repositorium-similarity-model\n",
      "Evaluating model on validation set...\n",
      "Pearson correlation: 0.1495 (p=0.1376)\n",
      "Spearman correlation: 0.1562 (p=0.1207)\n",
      "\n",
      "Sample predictions:\n",
      "Text 1: ['the 2d convection-diffusion is a well-known prob...\n",
      "Text 2: ['a visualização de relatórios de meios complement...\n",
      "Gold score: 0.1000, Predicted: 0.1504\n",
      "--------------------------------------------------------------------------------\n",
      "Text 1: ['on a business context, it is responsibility of t...\n",
      "Text 2: ['the reconstruction of genomic-scale metabolic mo...\n",
      "Gold score: 0.0000, Predicted: 0.0415\n",
      "--------------------------------------------------------------------------------\n",
      "Text 1: ['o koha é um software com interface web para gest...\n",
      "Text 2: ['devido à elevada proliferação tecnológica, exist...\n",
      "Gold score: 0.3000, Predicted: 0.1817\n",
      "--------------------------------------------------------------------------------\n",
      "Text 1: ['real-time monitoring has become one of the most ...\n",
      "Text 2: ['a saúde constitui um direito inegável dos cidadã...\n",
      "Gold score: 0.0000, Predicted: 0.0970\n",
      "--------------------------------------------------------------------------------\n",
      "Text 1: ['ao longo dos últimos anos, tem-se assistido a um...\n",
      "Text 2: ['a deteção de danos na estrutura externa de veícu...\n",
      "Gold score: 0.0667, Predicted: -0.0412\n",
      "--------------------------------------------------------------------------------\n",
      "Pearson correlation: 0.1495 (p=0.1376)\n",
      "Spearman correlation: 0.1562 (p=0.1207)\n",
      "\n",
      "Sample predictions:\n",
      "Text 1: ['the 2d convection-diffusion is a well-known prob...\n",
      "Text 2: ['a visualização de relatórios de meios complement...\n",
      "Gold score: 0.1000, Predicted: 0.1504\n",
      "--------------------------------------------------------------------------------\n",
      "Text 1: ['on a business context, it is responsibility of t...\n",
      "Text 2: ['the reconstruction of genomic-scale metabolic mo...\n",
      "Gold score: 0.0000, Predicted: 0.0415\n",
      "--------------------------------------------------------------------------------\n",
      "Text 1: ['o koha é um software com interface web para gest...\n",
      "Text 2: ['devido à elevada proliferação tecnológica, exist...\n",
      "Gold score: 0.3000, Predicted: 0.1817\n",
      "--------------------------------------------------------------------------------\n",
      "Text 1: ['real-time monitoring has become one of the most ...\n",
      "Text 2: ['a saúde constitui um direito inegável dos cidadã...\n",
      "Gold score: 0.0000, Predicted: 0.0970\n",
      "--------------------------------------------------------------------------------\n",
      "Text 1: ['ao longo dos últimos anos, tem-se assistido a um...\n",
      "Text 2: ['a deteção de danos na estrutura externa de veícu...\n",
      "Gold score: 0.0667, Predicted: -0.0412\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "\n",
    "# Load the best model (if available)\n",
    "try:\n",
    "    best_model_path = os.path.join(output_dir)\n",
    "    if os.path.exists(best_model_path):\n",
    "        model = SentenceTransformer(best_model_path)\n",
    "        print(f\"Loaded best model from {best_model_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not load best model. Using current model. Error: {e}\")\n",
    "\n",
    "# Evaluation on validation set\n",
    "print(\"Evaluating model on validation set...\")\n",
    "\n",
    "# Get embeddings for validation texts\n",
    "sentences1 = [ex.texts[0] for ex in val_examples]\n",
    "sentences2 = [ex.texts[1] for ex in val_examples]\n",
    "gold_scores = [ex.label for ex in val_examples]\n",
    "\n",
    "# Get embeddings and calculate cosine similarities\n",
    "embeddings1 = model.encode(sentences1, convert_to_tensor=True)\n",
    "embeddings2 = model.encode(sentences2, convert_to_tensor=True)\n",
    "\n",
    "cosine_scores = []\n",
    "for i in range(len(embeddings1)):\n",
    "    cosine_score = torch.nn.functional.cosine_similarity(embeddings1[i].unsqueeze(0), \n",
    "                                                        embeddings2[i].unsqueeze(0)).item()\n",
    "    cosine_scores.append(cosine_score)\n",
    "\n",
    "# Calculate correlation metrics\n",
    "pearson_corr, pearson_p = pearsonr(gold_scores, cosine_scores)\n",
    "spearman_corr, spearman_p = spearmanr(gold_scores, cosine_scores)\n",
    "\n",
    "print(f\"Pearson correlation: {pearson_corr:.4f} (p={pearson_p:.4f})\")\n",
    "print(f\"Spearman correlation: {spearman_corr:.4f} (p={spearman_p:.4f})\")\n",
    "\n",
    "# Sample predictions\n",
    "print(\"\\nSample predictions:\")\n",
    "for i in range(min(5, len(val_examples))):\n",
    "    print(f\"Text 1: {sentences1[i][:50]}...\")\n",
    "    print(f\"Text 2: {sentences2[i][:50]}...\")\n",
    "    print(f\"Gold score: {gold_scores[i]:.4f}, Predicted: {cosine_scores[i]:.4f}\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "# Save evaluation metrics\n",
    "evaluation_results = {\n",
    "    \"pearson_correlation\": pearson_corr,\n",
    "    \"spearman_correlation\": spearman_corr,\n",
    "    \"num_validation_examples\": len(val_examples)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e455bf3",
   "metadata": {},
   "source": [
    "## Information Retrieval Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718b88e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(query, documents, top_k=5, model=model):\n",
    "    try:\n",
    "        if not documents:\n",
    "            print(\"Warning: Empty document list provided\")\n",
    "            return []\n",
    "            \n",
    "        query_embedding = model.encode(query, convert_to_tensor=True, show_progress_bar=False)\n",
    "        \n",
    "        # Get document abstracts\n",
    "        doc_abstracts = []\n",
    "        for doc in documents:\n",
    "            abstract = doc.get('dc.description.abstract', '')\n",
    "            # Skip empty abstracts\n",
    "            if abstract:\n",
    "                doc_abstracts.append(abstract)\n",
    "            \n",
    "        # Encode all documents\n",
    "        doc_embeddings = model.encode(doc_abstracts, \n",
    "                                     convert_to_tensor=True, \n",
    "                                     show_progress_bar=(len(doc_abstracts) > 10))\n",
    "        \n",
    "        # Calculate similarities\n",
    "        import torch.nn.functional as F\n",
    "        similarities = F.cosine_similarity(query_embedding.unsqueeze(0), doc_embeddings)\n",
    "        \n",
    "        # Sort by similarity\n",
    "        results = []\n",
    "        for i, sim in enumerate(similarities):\n",
    "            # Find the original document that corresponds to this abstract\n",
    "            for j, doc in enumerate(documents):\n",
    "                if doc.get('dc.description.abstract', '') == doc_abstracts[i]:\n",
    "                    results.append((doc, sim.item()))\n",
    "                    break\n",
    "        \n",
    "        # Return top k results\n",
    "        return sorted(results, key=lambda x: x[1], reverse=True)[:top_k]\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error in retrieve function: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11ceac0",
   "metadata": {},
   "source": [
    "## Testing the Information Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205719ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1000 documents\n"
     ]
    }
   ],
   "source": [
    "# Load document collection\n",
    "collection_file = data_dir / \"col_1822_21316_processed.json\"\n",
    "\n",
    "try:\n",
    "    with open(collection_file, 'r', encoding='utf-8') as f:\n",
    "        documents = json.load(f)\n",
    "    print(f\"Loaded {len(documents)} documents\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error loading document collection: {e}\")\n",
    "    print(\"Creating empty document list\")\n",
    "    documents = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5873c585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Query: 'processamento de linguagem natural'\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 32/32 [00:08<00:00,  3.79it/s]\n",
      "Batches: 100%|██████████| 32/32 [00:08<00:00,  3.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 results:\n",
      "\n",
      "Document 1 - Similarity: 0.5115\n",
      "Title: unfuzzying fuzzy parsing\n",
      "Authors: carvalho, pedro miguel de jesus ventura\n",
      "Abstract: ['recognizing sentences of a language in an efficient and precise manner has always been a strong subject within computer science. many theories, algorithms and techniques have been proposed along computing history, but at the end it all comes down to performing lexical and syntactic analysis of the source, originating a parse tree as the result. sometimes there is no need for full precision or even a full parse tree. a good example of one of these cases is architecture extraction from source code. in this case only a small portion of the code is of interest. another good example is recognizing handwritten expressions, because it is entirely impossible to predict the kind of calligraphy that will be analyzed, it is also impossible to perform an one hundred percent precise recognition. this need for tolerant parsing lead to the development of many forms of tolerant parsing along the years. this master work will focus on one form of tolerant parsing in particular, fuzzy parsing. from this work it is expected the emergence of a new fuzzy parsing technique based on automata, where automata states would represent context and edges would represent potential matches inside that context. the hypothesis of this work is that such an approach reduces uncertainty and recognition time. it is also expected the creation of a tool suit that facilitates the process of developing fuzzy parsers. we believe that such a tool will be a great addition to areas such as program comprehension or ide construction.', 'reconhecer frases de uma linguagem, de uma forma eficiente e precisa, tem sido sempre um tópico de interesse dentro da informática. diversas teorias, algoritmos e técnicas foram propostas ao longo dos anos, mas no fim de contas tudo se baseia em análises léxicas, sintáticas e semânticas da fonte, originando uma árvore de parsing como resultado. por vezes não há necessidade de um reconhecimento cem por cento preciso, nem de uma árvore de parsing completa. um bom exemplo de um desses casos, pode ser encontrado na extração de modelos arquiteturais a partir de código fonte. neste caso, apenas uma parte reduzida do código tem interesse. outro bom exemplo pode ser encontrado no reconhecimento de expressões matemáticas escritas manualmente. uma vez que é impossível prever o tipo de caligrafia a ser analisada, é também impossível realizar um reconhecimento cem por cento preciso. esta necessidade por tolerância no reconhecimento levou ao desenvolvimento de várias técnicas de parsing tolerante ao longo dos anos. esta dissertação irá focar-se particularmente numa forma de parsing tolerante, fuzzy parsing. deste trabalho é esperado que surja uma nova técnica de fuzzy parsing baseada em autómatos, onde os estados representarão contexto e os arcos representarão possíveis correspondências dentro desse contexto. espera-se que esta abordagem reduza a incerteza e o tempo de reconhecimento. é também esperado que seja criada uma ferramenta que facilite o processo de criação de outros fuzzy parsers. pensamos que uma ferramenta do género será uma bela adição ao para áreas como análise de programas e construção de ambientes de desenvolvimento de software.']\n",
      "Keywords: ['fuzzy parsing', 'ide construction', 'program comprehension', 'automata', 'grammars']\n",
      "\n",
      "Document 2 - Similarity: 0.4312\n",
      "Title: avaliação automática de testes de atenção e acuidade visual\n",
      "Authors: pereira, mariana de oliveira\n",
      "Abstract: ['in recent years, our research group on language processing, gepl, has been collaborating with centro neurosensorial de braga, led by dr. ana paula azevedo. in this context, some serious games were developed and installed for recognizing shapes, emotions and training central and peripheral vision. they are used in memory therapy, deconcentration, dyslexia, and other problems that affect the acquisition of knowledge in learning processes.the ideas that rose up along the literature review done on those areas, will be exposed along the state-of-the-art chapter in this report. this thesis proposes a system that will implement an error detection algorithm based on speech-to-text analysis to check whether the spoken sequence contains errors or not. as the system is intended to be installed in the neurosensory center, the results will be presented visually to help the therapist in their day-to-day work and monitor the actual use of the system.', 'nos últimos anos, o nosso grupo de investigação em processamento de linguagens, gepl, tem vindo a colaborar com o centro neurossensorial de braga, liderado pela drª ana paula azevedo. neste contexto, foram desenvolvidos e instalados alguns jogos sérios para reconhecimento de formas e de emoções e para treino da visão central e periférica. estes são usados na terapia da memória, desconcentração, dislexia e outras perturbaçoes que afetam a aquisição de conhecimentos em processos de aprendizagem. as ideias que surgiram, no decorrer da revisão, de literatura feita sobre essas áreas serão expostas ao longo do capítulo de estado da arte deste relatório. esta tese propõe um sistema que implementará um algoritmo de deteção de erros baseado na análise de fala para texto de modo verificar se a sequência falada contém erros ou não. como o sistema se destina a ser instalado no centro neurossensorial, os resultados serão apresentados visualmente para auxiliar o terapeuta no seu dia-a-dia e monitorar o real uso do sistema.']\n",
      "Keywords: ['serious games', 'speech recognition', 'jogos sérios', 'reconhecimento de fala']\n",
      "\n",
      "Document 3 - Similarity: 0.4085\n",
      "Title: contributions for building a corpora-flow system\n",
      "Authors: santos, andré fernandes\n",
      "Abstract: ['os corpora textuais são um recurso importante no processamento de linguagem natural e em áreas relacionadas, tais como a mineração de textos biomédicos, a linguística de corpus, aprendizagem máquina e recuperação de informação. a preparação de documentos para inclusão num corpus envolve vários passos distintos e uma rede complexa de dependências e condições, que resulta num fluxo difícil de gerir manualmente. esta dissertação foca-se nos diversos desafios encontrados no processo de construção de corpora, e propõe métodos para ultrapassar essas questões. o primeiro problema abordado foi a limpeza de documentos de texto –remoção de resíduos estruturais, normalização de formatos e notações e deteção de delimitadores de secção– tornando os documentos passíveis de serem processados. outra questão abordada foi a deteção de documentos duplicados e de pares de documentos candidatos a alinhamento, tendo sido introduzido e implementado um método para medição da similaridade entre documentos. posteriormente, introduziu-se o conceito de sincronização de documentos, seguido da descrição de uma implementação baseada nos delimitadores de secção. dois casos de estudo reais foram utilizados para guiar a implementação das ferramentas desenvolvidas: alinhamento multi-língua de documentos para inclusão em corpora paralelos alinhados e a construção de corpora de textos biomédicos para mineração de texto. um protótipo de um sistema de gestão da construção de corpora foi desenvolvido – um sistema de corpora-flow. este sistema incorpora mecanismos que facilitam a implementação do fluxo necessário para a construção de um corpus. uma avaliação comparativa do conjunto de ferramentas desenvolvido foi realizada através do alinhamento de documentos com e sem a intervenção das ferramentas desenvolvidas. um pequeno conjunto de ferramentas foi desenvolvido para avaliar os resultados de alinhamentos.', 'text corpora are important resources on natural language processing and related areas such as biomedical text mining, corpus linguistics, machine learning and information extraction. preparing documents to be included in a corpus involves several different steps and a complex network of dependencies and conditions, which results in a workflow difficult to manage manually. this dissertation focuses on different challenges which can be found when building corpora, and proposed methods to overcome such questions. cleaning of text documents – removing structural residues, normalizing encodings and notations and finding section delimiters – to make the documents suitable for further processing. another question addressed was the detection of duplicated documents and candidate document pairs for alignment. a method for measuring the similarity between documents was introduced and implemented. then, the concept of document synchronization was introduced, followed by the description of an implementation based on section delimiters. two real-world scenarios were used to guide the implementation of the tools developed: multi-language document alignment for inclusion in parallel aligned corpora and building corpora of biomedical texts for text mining. a prototype of a corpora building management system was developed – a corpora-flow system. this system includes mechanisms which facilitate the implementation of the workflow needed to build a corpus. a comparative evaluation of the set of tools developed was performed by aligning documents with and without using the tools developed. a small set of auxiliary tools was created to evaluate the results of alignments.']\n",
      "Keywords: None\n",
      "\n",
      "================================================================================\n",
      "Query: 'web performance optimization'\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 32/32 [00:08<00:00,  3.78it/s]\n",
      "Batches: 100%|██████████| 32/32 [00:08<00:00,  3.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 results:\n",
      "\n",
      "Document 1 - Similarity: 0.3808\n",
      "Title: on the performance of webassembly\n",
      "Authors: macedo, joão gonçalves de\n",
      "Abstract: ['the worldwide web has dramatically evolved in recent years. web pages are dynamic, expressed by pro grams written in common programming languages given rise to sophisticated web applications. thus, web browsers are almost operating systems, having to interpret/compile such programs and execute them. although javascript is widely used to express dynamic web pages, it has several shortcomings and performance inefficiencies. to overcome such limitations, major it powerhouses are developing a new portable and size/load efficient language: webassembly. in this dissertation, we conduct the first systematic study on the energy and run-time performance of webassembly and javascript on the web. we used micro-benchmarks and real applications to have more realistic results. the results show that webassembly, while still in its infancy, is starting to already outperform javascript, with much more room to grow. a statistical analysis indicates that webassembly produces significant performance differences compared to javascript. however, these differences differ between micro-benchmarks and real-world benchmarks. our results also show that webassembly improved energy efficiency by 30%, on average, and show how different webassembly behaviour is among three popular web browsers: google chrome, microsoft edge, and mozilla firefox. our findings indicate that webassembly is faster than javascript and even more energy-efficient. our benchmarking framework is also available to allow further research and replication.', 'a web evoluiu dramaticamente em todo o mundo nos últimos anos. as páginas web são dinâmicas, expressas por programas escritos em linguagens de programação comuns, dando origem a aplicativos web sofisticados. assim, os navegadores web são quase como sistemas operacionais, tendo que interpre tar/compilar tais programas e executá-los. embora o javascript seja amplamente usado para expressar páginas web dinâmicas, ele tem várias deficiências e ineficiências de desempenho. para superar tais limitações, as principais potências de ti estão a desenvolver uma nova linguagem portátil e eficiente em tamanho/carregamento: webassembly. nesta dissertação, conduzimos o primeiro estudo sistemático sobre o desempenho da energia e do tempo de execução do webassembly e javascript na web. usamos micro-benchmarks e aplicações reais para obter resultados mais realistas. os resultados mostram que webassembly, embora ainda esteja na sua infância, já está começa a superar o javascript, com muito mais espaço para crescer. uma análise estatística indica que webassembly produz diferenças de desempenho significativas em relação ao javascript. no entanto, essas diferenças diferem entre micro-benchmarks e benchmarks de aplicações reais. os nossos resultados também mostram que o webassembly melhorou a eficiência energética em 30%, em média, e mostram como o comportamento do webassembly é diferente entre três navegadores web populares: google chrome, microsoft edge e mozilla firefox. as nossas descobertas indicam que o webassembly é mais rápido que o javascript e ainda mais eficiente em termos de energia. a nossa benchmarking framework está disponível para permitir pesquisas adicionais e replicação.']\n",
      "Keywords: ['energy efficiency', 'green software', 'web browsers', 'webassembly', 'eficiência energética', 'navegadores web', 'software verde']\n",
      "\n",
      "Document 2 - Similarity: 0.3516\n",
      "Title: query optimizers based on machine learning techniques\n",
      "Authors: souto, rui pedro sousa rodrigues do\n",
      "Abstract: ['query optimizers are considered one of the most relevant and sophisticated components in a database management system. however, despite currently producing nearly optimal results, optimizers rely on statistical estimates and heuristics to reduce the search space of alternative execution plans for a single query. as a result, for more complex queries, errors may grow exponentially, often translating into sub-optimal plans resulting in less than ideal performance. recent advances in machine learning techniques have opened new opportunities for many of the existing problems related to system optimization. this document proposes a solution built on top of postgresql that learns to select the most efficient set of optimizer strategy settings for a particular query. instead of depending entirely on the optimizer’s estimates to compare different plans under different configurations, it relies on a greedy selection algorithm that supports several types of predictive modeling techniques, from more traditional modeling techniques to a deep learning approach. the system is evaluated experimentally with the standard tpc-h and join order ing benchmark workloads to measure the cost and benefits of adding machine learning capabilities to traditional query optimizers.', 'os otimizadores de queries são considerados um dos componentes de maior relevância e complexidade num sistema de gestão de bases de dados. no entanto, apesar de atualmente produzirem resultados quase ótimos, os otimizadores dependem do uso de estimativas estatísticas e de heurísticas para reduzir o espaço de procura de planos de execução alternativos para uma determinada query. como resultado, para queries mais complexas, os erros podem crescer exponencialmente, o que geralmente se traduz em planos sub-ótimos, resultando num desempenho inferior ao ideal. os recentes avanços nas técnicas de aprendizagem automática abriram novas oportunidades para muitos dos problemas existentes relacionados com otimização de sistemas. este documento propõe uma solução construída sobre o postgresql que aprende a selecionar o conjunto mais eficiente de configurações do otimizador para uma determinada query. em vez de depender inteiramente de estimativas do otimizador para comparar planos de configurações diferentes, a solução baseia-se num algoritmo de seleção greedy que suporta vários tipos de técnicas de modelagem preditiva, desde técnicas mais tradicionais a uma abordagem de deep learning. o sistema é avaliado experimentalmente com os workloads tpc-h e join ordering benchmark para medir o custo e os benefícios de adicionar aprendizagem automática a otimizadores de queries tradicionais.']\n",
      "Keywords: ['database tuning', 'machine learning', 'query optimization', 'aprendizagem automática', 'otimização de queries', 'tuning de base de dados']\n",
      "\n",
      "Document 3 - Similarity: 0.3304\n",
      "Title: utilização dos templates e modelos do django para desenvolver aplicações web de elevado desempenho\n",
      "Authors: fernandes, joão miguel gonçalves\n",
      "Abstract: ['this document describes the development of high performance web applications using django framework. initially, the operation and usage mode of django are introduced, as well as several web applications’ latency reduction techniques. the work carried out fo cused on the design, implementation and performance optimization of a web application, which consists of an article sharing system. the development process followed the scrum methodology. during development, several technologies were explored, such as memcached, celery and varnish, which enabled the implementation of certain performance optimi zation strategies. the latency of several operations was measured, before and after the application of optimization techniques, in order to ensure that one was moving in the right direction. the optimization of the application’s performance was performed at various le vels, including the transfer of content across the network and the backend services. http caching, data compression and minification tecniques, as well as static content replication using content delivery networks, were used. partial update of the application’s pages on the front-end and asynchronous processing techniques were applied. the database utili zation was optimized by creating indexes and by taking advantage of a nosql solution. memory caching strategies, with distinct granularities, were implemented to store templa tes and application objects. furthermore, asynchronous task queues were used to perform some costly operations. all of the aforementioned techniques favorably contributed to the web application’s latency decrease. django only supports the application of some of these techniques, because it operates on the back-end. since performance must be optimized at various levels, it was necessary to use other tools besides django.', 'este documento descreve o desenvolvimento de aplicações web de elevado desempenho com a framework django. inicialmente, apresenta-se o funcionamento e o modo de utiliza ção do django, bem como diversas técnicas de diminuição da latência das aplicações web. o trabalho realizado focou-se na conceção, implementação e otimização do desempenho de uma aplicação web, que consiste num sistema de partilha de artigos. o processo de desenvolvimento seguiu a metodologia scrum. durante o desenvolvimento foram explo radas diversas tecnologias, tais como memcached, celery e varnish, que possibilitaram a implementação de determinadas estratégias de otimização do desempenho. realizaram-se medições da latência de diversas operações, antes e após a aplicação das estratégias de oti mização, para garantir que se caminhava no sentido correto. a otimização do desempenho da aplicação ocorreu a vários níveis, incluindo a transferência do conteúdo pela rede e os serviços de back-end. utilizaram-se técnicas como o caching http, bem como a compressão e minificação de informação e, ainda, a replicação de conteúdo estático utilizando content delivery networks. aplicaram-se técnicas de processamento assíncrono e atualização parcial das páginas da aplicação no front-end. otimizou-se a utilização da base de dados, criando índices e tirando partido de uma solução nosql. implementaram-se estratégias de caching em memória com granularidades distintas, para armazenar templates e objetos gerados pela aplicação. recorreu-se ainda a filas assíncronas de tarefas para a realização de algumas operações custosas. todas as técnicas mencionadas contribuíram favoravelmente para a di minuição da latência da aplicação web. o django apenas suporta a aplicação de algumas destas técnicas, já que opera no back-end. como o desempenho deve ser otimizado a vários níveis, foi necessário recorrer a outras ferramentas para além do django.']\n",
      "Keywords: None\n",
      "\n",
      "================================================================================\n",
      "Query: 'machine learning applications'\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 32/32 [00:08<00:00,  3.71it/s]\n",
      "Batches: 100%|██████████| 32/32 [00:08<00:00,  3.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 results:\n",
      "\n",
      "Document 1 - Similarity: 0.5999\n",
      "Title: in-vehicle object detection with yolo algorithm\n",
      "Authors: farinha, joão simões\n",
      "Abstract: ['with the growing computational power that we have at our disposal and the ever-increasing amount of data available the field of machine learning has given rise to deep learning, a subset of machine learning algorithms that have shown extraordinary results in a variety of applications from natural language processing to computer vision. in the field of computer vision, these algorithms have greatly improved the state-of-the-art accuracy in tasks associated with object recognition such as detection. this thesis makes use of one of these algorithms, specifically the yolo algorithm, as a basis in the development of a system capable of detecting objects laying inside a car cockpit. to this end a dataset is collected for the purpose of training the yolo algorithm on this task. a comparative analysis of the detection performance of the yolov2 and yolov3 architectures is performed.several experiments are performed by modifying the yolov3 architecture to attempt to improve its accuracy. specifically tests are performed in regards to network size, and the multiple outputs present in this network. explorative experiments are done in order to test the effect that parallel network might have on detection performance. lastly tests are done to try to find an optimal learning rate and batch size for our dataset on the new architectures.', 'com o crescente poder computacional que temos à nossa disposição e o aumento da quantidade dados a que temos acesso o campo de machine learning deu origem ao deep learning um subconjunto de algoritmos de machine learning que têm demonstrado resultados extraordinários numa variedade de aplicações desde processamento de linguagens naturais a visão por computador. no campo de visão por computador estes algoritmos têm levado a enormes progressos na correção de sistemas de deteção de objetos. nesta tese usamos um destes algoritmos, especificament o yolo, como base para desenvolver um sistema capaz de detetar objetos dentro de um carro. dado isto um dataset é recolhido com o propósito de treinar o algoritmo yolo nesta tarefa. uma analise comparativa da correção dos algoritmos yolov2 e yolov3 ´e realizada. várias técnicas relacionadas com a modificação da arquitetura yolov3 são exploradas para otimizar o sistema para o problema especifico de deteção a bordo de veículos. especificamente testes são realizados no contexto de tamanho da rede e dos múltiplos outputs presentes nesta rede. experiencias exploratórias são realizadas de forma a testar o efeito que redes parallelas podem ter na correção dos algoritmos. por fim testes são feitos para tentar encontrar learning rates e batch sizes apropriados para o nosso dataset nas novas arquiteturas.']\n",
      "Keywords: None\n",
      "\n",
      "Document 2 - Similarity: 0.5927\n",
      "Title: automation of machine learning models benchmarking\n",
      "Authors: sá, joão pedro barros\n",
      "Abstract: [\"na área de ciência de dados, o machine learning está-se a revelar uma ferramenta essencial para resolver problemas complexos. as empresas estão a investir em equipas de ciência de dados e machine learning para desenvolver modelos que apresentem valor para os clientes. no entanto, estes modelos são uma pequena percentagem de uma pipeline de projetos de machine learning (ml) e, para entregar um produto de ml completo, é necessário um número maior de componentes. devops é uma mentalidade de engenharia e um conjunto de práticas que visa unificar o processo de desenvolvimento e o processo de operações em um software, mlops é um conceito similar a devops mas aplicado ao desenvolvimento e entrega de soluções de ml. o nível de automatização das etapas em uma pipeline de ml define a maturidade do processo de ml, que reflete a velocidade de treino de novos modelos com novos dados ou de treino de novos modelos com diferentes implementações. um sistema de ml é um sistema de software, desenvolvimento e atualizações contínuas são necessárias para garantir um sistema que escale conforme as necessidades. o principal objetivo desta tese é apoiar a criação de um sistema integrado de ml com uma arquitetura que proporcione a capacidade de ser continuamente operada em um ambiente de produção. um conceito para avaliação de desempenho de algoritmos deve ser elaborado e implementado. o principal obetivo e melhorar e ace'erar o cicio de desenvolvimento de modelos de ml na empresa. para atingir este objetivo surge a necessidade de definir uma arquitetura com especificações e a implementação de processos automatizadas num pipeline de ml existente, este processo têm como objetivo alcançar uma ferramenta de benchmark de modelos, com capacidade de analisar o desempenho do modelo, um motor de inferência e um banco de dados para armazenar todas as métricas computadas. um sistema baseado em ia em desenvolvimento fornece o caso de estudo para desenvolver e validar a arquitetura. os avanços atuais na área da condução semiautomática introduz a necessidade de sistemas de monitoramento que podem localizar e detectar eventos especificas no veículo. os conjuntos de sensores são instalados dentro da cabine para alimentar sistemas inteligentes que visam analisar e sinalizar certos comportamentos que podem impactar a segurança e o conforto dos passageiros..\", 'in the field of data science, ml is proving to be a core feature to solve complex real-world problems. businesses are investing in data science and ml teams to develop ai based models that can deliver business value to their users. however, these models are only a small fraction of an ml project pipeline, and to deliver an end to end ml product, a greater number of components are needed. devops is an engineering mindset and a set of practices that aims to unify the development process and the operation process on software. mlops is a similar concept to devops but applicable to the development and delivery of ml based solutions. the automation of the steps in a ml pipeline defines the maturity of the ml process, reflecting the velocity of training new models given new data or training new models given new implementations. an ml system is a software system that can support development, provide continuous integration and continuous delivery apply to help guarantee that one can reliably build and operate ml systems at scale. the main objective of this thesis are to support the creation of an integrated ml system with an archi tecture that provides the ability to be continuously operated in a production-like environment. furthermore, a concept to evaluate the performance of algorithms shall be devised and implemented. the end goal is to improve and accelerate the ml development lifecycle. to achieve this goal surges the need to define an architecture alongside specifications and the implementation of several automated steps into an existing ml pipeline. to improve and accelerate model development an model engine benchmark tool is devised capable of several features, including the ability to have dashboards for model performance evaluation, an automatic inference engine, performance metrics for the model and a database to store all the computed metrics and metadata. an ai-based system under development provides the case study to develop and validate this architec ture. the current advances of semi-automated driving introduce the need for monitoring systems to scan and detect specific events in the vehicle. sensor clusters are installed inside the vehicle cabin to feed data to intelligent systems that aim to analyze and red flag certain behaviours that can potentially impact passengers safety and comfort while using the vehicle.']\n",
      "Keywords: ['engenharia software', 'aprendizagem máquina', 'ciência dados', 'devops', 'mlops', 'machine learning', 'software', 'data science', 'pipelines', 'automation']\n",
      "\n",
      "Document 3 - Similarity: 0.5915\n",
      "Title: fault tolerant decentralized deep neural networks\n",
      "Authors: padrão, joão carlos faria\n",
      "Abstract: ['machine learning is trending in computer science, especially deep learning. training algorithms that follow this approach to machine learning routinely deal with vast amounts of data. processing these enormous quantities of data requires complex computation tasks that can take a long time to produce results. distributing computation efforts across multiple machines makes sense in this context, as it allows conclusive results to be available in a shorter time frame. distributing the training of a deep neural network is not a trivial procedure. various architectures have been proposed, following two different paradigms. the most common one follows a centralized approach, where a centralized entity, broadly named parameter server, synchronizes and coordinates the updates generated by a number of workers. the alternative discards the centralized unit, assuming a decentralized architecture. the synchronization between the multiple workers is assured by communication techniques that average gradients between a node and its peers. high-end clusters are the ideal environment to deploy deep learning systems. low latency between nodes assures low idle times for workers, increasing the overall system performance. these setups, however, are expensive and are only available to a limited number of entities. on the other end, there is a continuous growth of edge devices with potentially vast amounts of available computational resources. in this dissertation, we aim to implement a fault tolerant decentralized deep neural net work training framework, capable of handling the high latency and unreliability characteristic of edge networks. to manage communication between nodes, we employ decentralized algorithms capable of estimating parameters globally', 'machine learning, mais especificamente deep learning, é um campo emergente nas ciências da computação. algoritmos de treino aplicados em deep learning lidam muito frequentemente com vastas quantidades de dados. processar estas enormes quantidades de dados requer operações computacionais complexas que demoram demasiado tempo para produzir resultados. distribuir o esforço computacional por múltiplas máquinas faz todo o sentido neste contexto e permite um aumento significativo de desempenho. distribuir o método de treino de uma rede neuronal não é um processo trivial. várias arquiteturas têm sido propostas, seguindo dois diferentes paradigmas. o mais comum segue uma abordagem centralizada, onde uma entidade central, normalmente denominada de parameter server, sincroniza e coordena todas as atualizações produzidas pelos workers. a alternativa passa por descartar a entidade centralizada, assumindo uma arquitetura descentralizada. a sincronização entre workers é assegurada através de estratégias de comunicação descentralizadas. clusters de alta performance são o ambiente ideal para a implementação de sistemas de deep learning. a baixa latência entre nodos assegura baixos períodos de inatividade nos workers, aumentando assim o rendimento do sistema. estas instalações, contudo, são muito custosas, estando apenas disponíveis para um pequeno número de entidades. por outro lado, o número de equipamentos nas extremidades da rede, com baixo aproveitamento de poder computacional, continua a crescer, o que torna o seu uso desejável. nesta dissertação, visamos implementar um ambiente de treino de redes neuronais descentralizado e tolerante a faltas, apto a lidar com alta latência nas comunicações e baixa estabilidade nos nodos, caraterística de redes na extremidade. para coordenar a comunicação entre os nodos, empregamos algoritmos de agregação, capazes de criar uma visão geral de parâmetros numa topologia.']\n",
      "Keywords: ['distributed systems', 'machine learning', 'artificial intelligence', 'fault tolerance', 'sistemas distribuídos', 'inteligência artificial', 'tolerância a faltas']\n"
     ]
    }
   ],
   "source": [
    "queries = [\n",
    "    \"processamento de linguagem natural\",\n",
    "    \"web performance optimization\",\n",
    "    \"machine learning applications\"\n",
    "]\n",
    "\n",
    "for query in queries:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Query: '{query}'\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    try:\n",
    "        results = retrieve(query, documents, top_k=3)\n",
    "        \n",
    "        if results:\n",
    "            print(f\"Top {len(results)} results:\")\n",
    "            for i, (doc, sim) in enumerate(results, 1):\n",
    "                print(f\"\\nDocument {i} - Similarity: {sim:.4f}\")\n",
    "                print(f\"Title: {doc.get('dc.title', 'No title')}\")\n",
    "                print(f\"Authors: {doc.get('dc.contributor.author', 'Unknown')}\")\n",
    "                \n",
    "                abstract = doc.get('dc.description.abstract', 'No abstract')\n",
    "                if len(abstract) > 200:\n",
    "                    print(f\"Abstract: {abstract[:200]}...\")\n",
    "                else:\n",
    "                    print(f\"Abstract: {abstract}\")\n",
    "                    \n",
    "                print(f\"Keywords: {doc.get('dc.subject', 'None')}\")\n",
    "        else:\n",
    "            print(\"No results found for this query.\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error testing retrieval: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
