{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c211ab9c",
   "metadata": {},
   "source": [
    "# Fine-tuning a model for Sentence Similarity and Information Retrieval\n",
    "\n",
    "In this notebook, we will fine-tune a sentence transformer model for document similarity tasks, specifically for the RepositoriUM collection. We'll use a pre-trained model and fine-tune it on pairs of document abstracts with similarity scores.\n",
    "\n",
    "The completed system will allow us to:\n",
    "1. Process document collections from RepositoriUM\n",
    "2. Train a similarity model on document pairs\n",
    "3. Retrieve relevant documents based on a query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b235e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (3.3.2)\n",
      "Requirement already satisfied: transformers in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (4.52.4)\n",
      "Requirement already satisfied: sentence-transformers in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (4.1.0)\n",
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (1.26.0)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (4.67.1)\n",
      "Requirement already satisfied: evaluate in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (0.4.3)\n",
      "Requirement already satisfied: huggingface_hub in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (0.32.4)\n",
      "Requirement already satisfied: torch in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (2.6.0)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from datasets) (3.13.3)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from datasets) (19.0.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: requests>=2.32.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: xxhash in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\n",
      "Requirement already satisfied: aiohttp in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from datasets) (3.10.4)\n",
      "Requirement already satisfied: packaging in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from datasets) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from huggingface_hub) (4.12.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from huggingface_hub) (1.1.3)\n",
      "Requirement already satisfied: scikit-learn in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from sentence-transformers) (1.5.2)\n",
      "Requirement already satisfied: scipy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from sentence-transformers) (1.14.1)\n",
      "Requirement already satisfied: Pillow in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from sentence-transformers) (10.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch) (3.1.5)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from aiohttp->datasets) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from aiohttp->datasets) (1.18.3)\n",
      "Requirement already satisfied: idna>=2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from yarl<2.0,>=1.0->aiohttp->datasets) (3.10)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from yarl<2.0,>=1.0->aiohttp->datasets) (0.2.1)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "!pip install datasets transformers sentence-transformers pandas numpy tqdm evaluate huggingface_hub torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a490a5a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3929228c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate>=0.26.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (1.7.0)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from accelerate>=0.26.0) (1.26.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from accelerate>=0.26.0) (25.0)\n",
      "Requirement already satisfied: psutil in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from accelerate>=0.26.0) (7.0.0)\n",
      "Requirement already satisfied: pyyaml in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from accelerate>=0.26.0) (6.0.2)\n",
      "Requirement already satisfied: torch>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from accelerate>=0.26.0) (2.6.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from accelerate>=0.26.0) (0.32.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from accelerate>=0.26.0) (0.5.3)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (3.13.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (2024.12.0)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (4.12.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (1.1.3)\n",
      "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (3.1.5)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from sympy==1.13.1->torch>=2.0.0->accelerate>=0.26.0) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from jinja2->torch>=2.0.0->accelerate>=0.26.0) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->huggingface-hub>=0.21.0->accelerate>=0.26.0) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->huggingface-hub>=0.21.0->accelerate>=0.26.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->huggingface-hub>=0.21.0->accelerate>=0.26.0) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->huggingface-hub>=0.21.0->accelerate>=0.26.0) (2025.1.31)\n"
     ]
    }
   ],
   "source": [
    "# Install accelerate package for PyTorch training support\n",
    "!pip install 'accelerate>=0.26.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0ac5a838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "import sentence_transformers\n",
    "import torch\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cbe6bdfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.utils import send_example_telemetry\n",
    "\n",
    "send_example_telemetry(\"sentence_similarity_notebook\", framework=\"pytorch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c5a700",
   "metadata": {},
   "source": [
    "## Configuring the Model\n",
    "\n",
    "We'll set the parameters for our model training. For best results in sentence similarity tasks, we should use a pre-trained sentence-transformer model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "82f536d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected model: paraphrase-multilingual-MiniLM-L12-v2\n",
      "Training parameters: 4 epochs, batch size 16, learning rate 2e-05\n"
     ]
    }
   ],
   "source": [
    "# Model configuration\n",
    "model_checkpoint = \"paraphrase-multilingual-MiniLM-L12-v2\"\n",
    "batch_size = 16  # Adjust based on your GPU memory\n",
    "max_length = 512  # Maximum sequence length\n",
    "\n",
    "# Training parameters\n",
    "num_epochs = 4  # Number of training epochs (adjust as needed)\n",
    "warmup_ratio = 0.1  # Percentage of steps for warmup\n",
    "learning_rate = 2e-5  # Learning rate for training\n",
    "\n",
    "print(f\"Selected model: {model_checkpoint}\")\n",
    "print(f\"Training parameters: {num_epochs} epochs, batch size {batch_size}, learning rate {learning_rate}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01fa71fa",
   "metadata": {},
   "source": [
    "## Loading the Dataset\n",
    "\n",
    "First, we need to load the training data that was created by our `process_data.py` script.\n",
    "This data consists of pairs of document abstracts with similarity scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d392025c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 500 document pairs\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Load the training data\n",
    "data_dir = Path(\"data\")\n",
    "train_file = data_dir / \"training_data.json\"\n",
    "\n",
    "try:\n",
    "    with open(train_file, 'r', encoding='utf-8') as f:\n",
    "        training_data = json.load(f)\n",
    "\n",
    "    print(f\"Loaded {len(training_data)} document pairs\")\n",
    "    \n",
    "    # Convert to DataFrame for easier handling\n",
    "    # Make sure we handle the data consistently as lists\n",
    "    train_df = pd.DataFrame([\n",
    "        {\"abstract1\": item[0], \"abstract2\": item[1], \"similarity\": float(item[2])}\n",
    "        for item in training_data\n",
    "    ])\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error loading training data: {e}\")\n",
    "    print(\"Please run process_data.py first to create the training data, or check the file path\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcbe6dd8",
   "metadata": {},
   "source": [
    "Let's examine the distribution of similarity scores to understand our data better:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fd7dbd0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min similarity: 0.0\n",
      "Max similarity: 0.3\n",
      "Mean similarity: 0.1371096928071928\n",
      "Median similarity: 0.06666666666666667\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Check if we have enough data\n",
    "if len(train_df) > 0:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(train_df['similarity'], bins=20)\n",
    "    plt.title('Distribution of Similarity Scores')\n",
    "    plt.xlabel('Similarity Score')\n",
    "    plt.ylabel('Count')\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Min similarity: {train_df['similarity'].min()}\")\n",
    "    print(f\"Max similarity: {train_df['similarity'].max()}\")\n",
    "    print(f\"Mean similarity: {train_df['similarity'].mean()}\")\n",
    "    print(f\"Median similarity: {train_df['similarity'].median()}\")\n",
    "else:\n",
    "    print(\"Not enough data to display similarity distribution.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9d6a63",
   "metadata": {},
   "source": [
    "Now, let's prepare the data for training by splitting it into training and validation sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1ad61ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: 400 pairs\n",
      "Validation data: 100 pairs\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Check if we have enough data for a valid split\n",
    "if len(train_df) < 10:\n",
    "    print(\"Warning: Not enough data for a meaningful split. Consider generating more data.\")\n",
    "    # Create a simple split for demonstration\n",
    "    train_data = train_df.iloc[:int(len(train_df)*0.8)]\n",
    "    val_data = train_df.iloc[int(len(train_df)*0.8):]\n",
    "else:\n",
    "    # Split data into train and validation sets\n",
    "    train_data, val_data = train_test_split(train_df, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training data: {len(train_data)} pairs\")\n",
    "print(f\"Validation data: {len(val_data)} pairs\")\n",
    "\n",
    "# Check if we have a reasonable amount of training data\n",
    "if len(train_data) < 100:\n",
    "    print(\"\\nWARNING: Training with a small dataset may lead to poor model performance.\")\n",
    "    print(\"Consider collecting more data for better results.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b5d629",
   "metadata": {},
   "source": [
    "## Preparing the Model for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4d43bc49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-10 12:53:01 - Load pretrained SentenceTransformer: paraphrase-multilingual-MiniLM-L12-v2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on: cpu\n",
      "Model successfully loaded: SentenceTransformer(\n",
      "  (0): Transformer({'max_seq_length': 128, 'do_lower_case': False}) with Transformer model: BertModel \n",
      "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
      ")\n",
      "Model is on device: cpu\n",
      "Prepared 400 training examples and 100 validation examples\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, InputExample, losses\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import time\n",
    "\n",
    "# Set the device for the model\n",
    "device_str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Training on: {device_str}\")\n",
    "\n",
    "try:\n",
    "    # Load pretrained sentence-transformer model\n",
    "    model = SentenceTransformer(model_checkpoint, device=device_str)\n",
    "    print(f\"Model successfully loaded: {model}\")\n",
    "    \n",
    "    # Check model's current device\n",
    "    print(f\"Model is on device: {next(model.parameters()).device}\")\n",
    "\n",
    "    # Prepare training examples\n",
    "    train_examples = []\n",
    "    for _, row in train_data.iterrows():\n",
    "        # Convert to string if not already\n",
    "        abstract1 = str(row['abstract1']) if not isinstance(row['abstract1'], str) else row['abstract1']\n",
    "        abstract2 = str(row['abstract2']) if not isinstance(row['abstract2'], str) else row['abstract2']\n",
    "        \n",
    "        # Create input example with properly formatted texts\n",
    "        train_examples.append(InputExample(\n",
    "            texts=[abstract1, abstract2],\n",
    "            label=float(row['similarity'])\n",
    "        ))\n",
    "\n",
    "    # Prepare validation examples\n",
    "    val_examples = []\n",
    "    for _, row in val_data.iterrows():\n",
    "        # Convert to string if not already\n",
    "        abstract1 = str(row['abstract1']) if not isinstance(row['abstract1'], str) else row['abstract1']\n",
    "        abstract2 = str(row['abstract2']) if not isinstance(row['abstract2'], str) else row['abstract2']\n",
    "        \n",
    "        val_examples.append(InputExample(\n",
    "            texts=[abstract1, abstract2],\n",
    "            label=float(row['similarity'])\n",
    "        ))\n",
    "\n",
    "    # Create data loaders\n",
    "    train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "    # Create evaluator\n",
    "    evaluator = EmbeddingSimilarityEvaluator(\n",
    "        sentences1=[ex.texts[0] for ex in val_examples],\n",
    "        sentences2=[ex.texts[1] for ex in val_examples],\n",
    "        scores=[ex.label for ex in val_examples]\n",
    "    )\n",
    "    \n",
    "    print(f\"Prepared {len(train_examples)} training examples and {len(val_examples)} validation examples\")\n",
    "except Exception as e:\n",
    "    print(f\"Error preparing model: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93629c06",
   "metadata": {},
   "source": [
    "## Training the Model\n",
    "\n",
    "Now we'll train our model using the CosineSimilarityLoss which is appropriate for similarity tasks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aef7d0d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-10 12:53:05 - Save model to information_retrieval/output/repositorium-similarity-model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training for 4 epochs with 25 batches per epoch\n",
      "Warmup steps: 10\n",
      "Error during training: fp16 mixed precision requires a GPU (not 'mps').\n",
      "Partially trained model saved to: information_retrieval/output/repositorium-similarity-model\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import losses\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import logging\n",
    "\n",
    "# Enable logging to see the training progress\n",
    "logging.basicConfig(format='%(asctime)s - %(message)s',\n",
    "                    datefmt='%Y-%m-%d %H:%M:%S',\n",
    "                    level=logging.INFO)\n",
    "\n",
    "# Define loss function\n",
    "train_loss = losses.CosineSimilarityLoss(model)\n",
    "\n",
    "# Set up training parameters\n",
    "warmup_steps = int(len(train_dataloader) * num_epochs * warmup_ratio)\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "output_path = 'information_retrieval/output/repositorium-similarity-model'\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "print(f\"Starting training for {num_epochs} epochs with {len(train_dataloader)} batches per epoch\")\n",
    "print(f\"Warmup steps: {warmup_steps}\")\n",
    "\n",
    "# Track training time\n",
    "start_time = time.time()\n",
    "\n",
    "try:\n",
    "    # Train the model with progress bar and proper logging\n",
    "    model.fit(\n",
    "        train_objectives=[(train_dataloader, train_loss)],\n",
    "        evaluator=evaluator,\n",
    "        epochs=num_epochs,\n",
    "        warmup_steps=warmup_steps,\n",
    "        output_path=output_path,\n",
    "        show_progress_bar=True,\n",
    "        callback=None,\n",
    "        use_amp=True,\n",
    "        checkpoint_path=output_path,\n",
    "        checkpoint_save_steps=len(train_dataloader),  # Save checkpoint after each epoch\n",
    "        checkpoint_save_total_limit=1  # Keep only the latest checkpoint\n",
    "    )\n",
    "    \n",
    "    # Calculate and display training time\n",
    "    training_time = time.time() - start_time\n",
    "    print(f\"Training completed in {training_time:.2f} seconds ({training_time/60:.2f} minutes)\")\n",
    "    print(f\"Model saved to: {output_path}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error during training: {e}\")\n",
    "    # Try to save the model anyway\n",
    "    try:\n",
    "        model.save(output_path)\n",
    "        print(f\"Partially trained model saved to: {output_path}\")\n",
    "    except:\n",
    "        print(\"Could not save model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b1243e",
   "metadata": {},
   "source": [
    "## Evaluating the Model\n",
    "\n",
    "Let's evaluate our trained model on the validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eb885d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-10 12:53:08 - EmbeddingSimilarityEvaluator: Evaluating the model on the  dataset:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fine-tuned model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-10 12:53:13 - Cosine-Similarity :\tPearson: 0.1459\tSpearman: 0.1312\n",
      "2025-06-10 12:53:13 - Load pretrained SentenceTransformer: paraphrase-multilingual-MiniLM-L12-v2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Pearson score: 0.1459\n",
      "Validation Spearman score: 0.1312\n",
      "Loading baseline model for comparison...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-10 12:53:17 - EmbeddingSimilarityEvaluator: Evaluating the model on the  dataset:\n",
      "2025-06-10 12:53:25 - Cosine-Similarity :\tPearson: 0.1459\tSpearman: 0.1312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Pearson score: 0.1459\n",
      "Baseline Spearman score: 0.1312\n",
      "Pearson improvement: 0.0000\n",
      "Spearman improvement: 0.0000\n",
      "The fine-tuned model doesn't show improvement. Consider adjusting parameters or collecting more training data.\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model on validation set\n",
    "try:\n",
    "    print(\"Evaluating fine-tuned model...\")\n",
    "    val_score = evaluator(model)\n",
    "    print(f\"Validation Pearson score: {val_score['pearson_cosine']:.4f}\")\n",
    "    print(f\"Validation Spearman score: {val_score['spearman_cosine']:.4f}\")\n",
    "    \n",
    "    # Compare with baseline model\n",
    "    print(\"Loading baseline model for comparison...\")\n",
    "    baseline_model = SentenceTransformer(model_checkpoint, device=device_str)\n",
    "    baseline_score = evaluator(baseline_model)\n",
    "    print(f\"Baseline Pearson score: {baseline_score['pearson_cosine']:.4f}\")\n",
    "    print(f\"Baseline Spearman score: {baseline_score['spearman_cosine']:.4f}\")\n",
    "    \n",
    "    # Calculate improvement for each metric\n",
    "    pearson_improvement = val_score['pearson_cosine'] - baseline_score['pearson_cosine']\n",
    "    spearman_improvement = val_score['spearman_cosine'] - baseline_score['spearman_cosine']\n",
    "    \n",
    "    print(f\"Pearson improvement: {pearson_improvement:.4f}\")\n",
    "    print(f\"Spearman improvement: {spearman_improvement:.4f}\")\n",
    "    \n",
    "    if pearson_improvement > 0 or spearman_improvement > 0:\n",
    "        print(\"The fine-tuned model shows improvement over the baseline!\")\n",
    "    else:\n",
    "        print(\"The fine-tuned model doesn't show improvement. Consider adjusting parameters or collecting more training data.\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error during evaluation: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e455bf3",
   "metadata": {},
   "source": [
    "## Information Retrieval Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "718b88e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(query, documents, top_k=5, model=model):\n",
    "    try:\n",
    "        # Check if documents list is empty\n",
    "        if not documents:\n",
    "            print(\"Warning: Empty document list provided\")\n",
    "            return []\n",
    "            \n",
    "        # Encode query\n",
    "        query_embedding = model.encode(query, convert_to_tensor=True, show_progress_bar=False)\n",
    "        \n",
    "        # Get document abstracts, handling missing abstracts\n",
    "        doc_abstracts = []\n",
    "        for doc in documents:\n",
    "            abstract = doc.get('dc.description.abstract', '')\n",
    "            # Skip empty abstracts\n",
    "            if abstract:\n",
    "                doc_abstracts.append(abstract)\n",
    "            \n",
    "        # Skip processing if no valid abstracts\n",
    "        if not doc_abstracts:\n",
    "            print(\"Warning: No valid abstracts found in the documents\")\n",
    "            return []\n",
    "            \n",
    "        # Encode all documents\n",
    "        doc_embeddings = model.encode(doc_abstracts, \n",
    "                                     convert_to_tensor=True, \n",
    "                                     show_progress_bar=(len(doc_abstracts) > 10))\n",
    "        \n",
    "        # Calculate similarities\n",
    "        import torch.nn.functional as F\n",
    "        similarities = F.cosine_similarity(query_embedding.unsqueeze(0), doc_embeddings)\n",
    "        \n",
    "        # Sort by similarity\n",
    "        results = []\n",
    "        for i, sim in enumerate(similarities):\n",
    "            # Find the original document that corresponds to this abstract\n",
    "            for j, doc in enumerate(documents):\n",
    "                if doc.get('dc.description.abstract', '') == doc_abstracts[i]:\n",
    "                    results.append((doc, sim.item()))\n",
    "                    break\n",
    "        \n",
    "        # Return top k results\n",
    "        return sorted(results, key=lambda x: x[1], reverse=True)[:top_k]\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error in retrieve function: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11ceac0",
   "metadata": {},
   "source": [
    "## Testing the Information Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "205719ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1000 documents\n"
     ]
    }
   ],
   "source": [
    "# Load document collection\n",
    "collection_file = data_dir / \"col_1822_21316_processed.json\"\n",
    "\n",
    "try:\n",
    "    with open(collection_file, 'r', encoding='utf-8') as f:\n",
    "        documents = json.load(f)\n",
    "    print(f\"Loaded {len(documents)} documents\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error loading document collection: {e}\")\n",
    "    print(\"Creating empty document list\")\n",
    "    documents = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5873c585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Query: 'processamento de linguagem natural em portugus'\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|| 32/32 [00:34<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 results:\n",
      "\n",
      "Document 1 - Similarity: 0.6127\n",
      "Title: applying attribute grammars to teach linguistic rules\n",
      "Authors: sousa, manuel gouveia carneiro de\n",
      "Abstract: ['this document presents the topic applying attribute grammars to teach linguistic rules, at universidade do minho in braga, portugal. this thesis is focused on using the formalisms of attribute grammars in order to create a tool to help linguistic students learn the different rules of a natural language. the system developed, named lyntax, consists in a processor for a domain specific language which intends to enable the user to specify different kinds of sentence structures, and afterwards, test various phrases against said structures. the processor validates and evaluates the input given, generating a grammar which is specific to a previously chosen sentence. lastly, using antlr, a parser is generated for that specific grammar referred above. the processor built by antlr also creates a syntax tree that is presented to the user for analysis purposes. an interface that supports the specification of the language (written in lyntax dsl) was built, also allowing the use of the processor and the generation of the specific grammar, exempting the user from knowing the details of the process. within this document, the focus will be primarly dedicated to the analysis of the system and how each block was built. different examples of the processor in action will be shown and explained.', 'este documento refere-se a uma dissertao sobre o tpico aplicar gramticas de atribu tos no ensino de regras de lingustica, e ser concluda na universidade do minho em braga, portugal. esta dissertao pretende focar-se no uso dos formalismos das gramticas de atributos de maneira a criar uma ferramenta que ajude os alunos de lingustica a aprender as diversas regras da lngua natural. o sistema desenvolvido, denominado de lyntax, consiste em um processor para uma linguagem de domnio especfico cujo objetivo  o de permitir ao seu utilizador a possibili dade de especificar diversas estruturas de frases, e posteriormente, testar frases contra essas mesmas estruturas. o processador valida e avalia o input recebido, gerando uma gramtica especfica  frase previamente escolhida. por fim, usando uma ferramenta como o antlr, um parser  gerado para a gramtica especfica acima referida. o processador construdo pelo antlr tambm gera a rvore de syntax que  apresentada ao utilizador com o intuito de ser analisada. foi tambm criada uma interface que suporta a especificao da linguagem, permitindo tambm o uso do processador e a gerao da gramtica especfica, abstraindo assim o utilizador de quaisquer tipo de clculos. neste documento, o focus primrio ser dedicado  anlise do sistema e como cada bloco foi construdo. diferentes exemplos de uso do processador sero apresentados e explicados.']\n",
      "Keywords: ['linguistic', 'natural language processing', 'attribute grammar', 'lingustica', 'processamento de lngua natural', 'gramticas de atributo']\n",
      "\n",
      "Document 2 - Similarity: 0.5408\n",
      "Title: entity recognition in archival descriptions\n",
      "Authors: cunha, lus filipe da costa\n",
      "Abstract: ['at the moment, there is a vast amount of archival data spread across the portuguese archives, which keeps information from our ancestors times to the present day. most of this information was already transcribed to digital format, and the public can access it through archives online repositories. despite that, some of these documents are structured with many plain text fields without any annotations, making their content analyses difficult. in this thesis, we implemented several named entity recognition solutions to perform a semantic interpretation of the archival finding aids by extracting named entities like person, place, date, profession, and organization. these entities translate into crucial information about the context in which they are inserted. they can be used for several purposes with high confidence results, such as creating smart browsing tools by using entity linking and record linking techniques. in this way, the main challenge of this work was the creation of powerful ner models capable of producing high confidence results. in order to achieve high result scores, we annotated several corpora to train our machine learning algorithms in the archival domain. we also used different ml architectures such as maxent, cnns, lstms, and bert models. during the models validation, we created different environments to test the effect of the context proximity in the training data. finally, during the models training, we noticed a lack of available portuguese annotated data, limiting the potential of several nlp tasks. in this way, we developed an intelligent corpus annotator that uses one of our ner models to assist and accelerate the annotation process.', 'de momento, existe uma vasta quantidade de dados arquivsticos espalhados pelos arquivos portugueses, que guardam informaes desde os tempos dos nossos antepassados at aos dias de hoje. a maior parte desta informao j foi transcrita para o formato digital e encontra-se disponvel ao pblico atravs de repositrios online dos arquivos. apesar disso, alguns destes documentos esto estruturados com muitos campos de texto livre, sem quaisquer anotaes, o que pode dificultar a anlise do seu contedo. nesta tese, implementamos vrias solues de reconhecimento de entidades mencionadas, a fim de se realizar uma interpretao semntica sobre descries arquivsticas, extraindo entidades tais como pessoa, local, data, profisso e organizao. estes tipos de entidades traduzem-se em informao crucial sobre o contexto em que esto inseridas. com mtricas de confiana suficientemente elevadas, estas entidades podem ser utilizadas para diversos fins, como a criao de ferramentas de navegao inteligente por meio de tcnicas de entity linking e record linking. desta forma, o principal desafio deste trabalho consistiu na criao de poderosos modelos ner que fossem capazes de produzir resultados de elevada confiana. para alcanar tais resultados, anotamos vrios datasets para treinar os nossos prprios algoritmos de aprendizado de mquina no contexto arquivstico. para alm disso, usamos diferentes arquiteturas de ml tais como maxent, cnns, lstms e bert. durante a validao do modelo, criamos diferentes ambientes de teste de modo a testar o efeito da proximidade de contexto nos dados de treino. por fim, durante o treino dos modelos verificamos que existe pouca quantidade de dados disponveis anotados em portugus, o que pode limitar o potencial de vrias tarefas de nlp. desta forma, desenvolvemos um anotador de datasets inteligente que utiliza um dos nossos modelos de ner para auxiliar e acelerar o processo de anotao.']\n",
      "Keywords: ['named entity recognition', 'archival finding aids', 'machine learning', 'deep learning', 'bert', 'data annotation', 'reconhecimento de entidades mencionadas', 'descries arquivsticas', 'anotao de dados']\n",
      "\n",
      "Document 3 - Similarity: 0.5284\n",
      "Title: avaliao automtica de testes de ateno e acuidade visual\n",
      "Authors: pereira, mariana de oliveira\n",
      "Abstract: ['in recent years, our research group on language processing, gepl, has been collaborating with centro neurosensorial de braga, led by dr. ana paula azevedo. in this context, some serious games were developed and installed for recognizing shapes, emotions and training central and peripheral vision. they are used in memory therapy, deconcentration, dyslexia, and other problems that affect the acquisition of knowledge in learning processes.the ideas that rose up along the literature review done on those areas, will be exposed along the state-of-the-art chapter in this report. this thesis proposes a system that will implement an error detection algorithm based on speech-to-text analysis to check whether the spoken sequence contains errors or not. as the system is intended to be installed in the neurosensory center, the results will be presented visually to help the therapist in their day-to-day work and monitor the actual use of the system.', 'nos ltimos anos, o nosso grupo de investigao em processamento de linguagens, gepl, tem vindo a colaborar com o centro neurossensorial de braga, liderado pela dr ana paula azevedo. neste contexto, foram desenvolvidos e instalados alguns jogos srios para reconhecimento de formas e de emoes e para treino da viso central e perifrica. estes so usados na terapia da memria, desconcentrao, dislexia e outras perturbaoes que afetam a aquisio de conhecimentos em processos de aprendizagem. as ideias que surgiram, no decorrer da reviso, de literatura feita sobre essas reas sero expostas ao longo do captulo de estado da arte deste relatrio. esta tese prope um sistema que implementar um algoritmo de deteo de erros baseado na anlise de fala para texto de modo verificar se a sequncia falada contm erros ou no. como o sistema se destina a ser instalado no centro neurossensorial, os resultados sero apresentados visualmente para auxiliar o terapeuta no seu dia-a-dia e monitorar o real uso do sistema.']\n",
      "Keywords: ['serious games', 'speech recognition', 'jogos srios', 'reconhecimento de fala']\n",
      "\n",
      "================================================================================\n",
      "Query: 'web performance optimization'\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|| 32/32 [00:29<00:00,  1.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 results:\n",
      "\n",
      "Document 1 - Similarity: 0.5265\n",
      "Title: query optimizers based on machine learning techniques\n",
      "Authors: souto, rui pedro sousa rodrigues do\n",
      "Abstract: ['query optimizers are considered one of the most relevant and sophisticated components in a database management system. however, despite currently producing nearly optimal results, optimizers rely on statistical estimates and heuristics to reduce the search space of alternative execution plans for a single query. as a result, for more complex queries, errors may grow exponentially, often translating into sub-optimal plans resulting in less than ideal performance. recent advances in machine learning techniques have opened new opportunities for many of the existing problems related to system optimization. this document proposes a solution built on top of postgresql that learns to select the most efficient set of optimizer strategy settings for a particular query. instead of depending entirely on the optimizers estimates to compare different plans under different configurations, it relies on a greedy selection algorithm that supports several types of predictive modeling techniques, from more traditional modeling techniques to a deep learning approach. the system is evaluated experimentally with the standard tpc-h and join order ing benchmark workloads to measure the cost and benefits of adding machine learning capabilities to traditional query optimizers.', 'os otimizadores de queries so considerados um dos componentes de maior relevncia e complexidade num sistema de gesto de bases de dados. no entanto, apesar de atualmente produzirem resultados quase timos, os otimizadores dependem do uso de estimativas estatsticas e de heursticas para reduzir o espao de procura de planos de execuo alternativos para uma determinada query. como resultado, para queries mais complexas, os erros podem crescer exponencialmente, o que geralmente se traduz em planos sub-timos, resultando num desempenho inferior ao ideal. os recentes avanos nas tcnicas de aprendizagem automtica abriram novas oportunidades para muitos dos problemas existentes relacionados com otimizao de sistemas. este documento prope uma soluo construda sobre o postgresql que aprende a selecionar o conjunto mais eficiente de configuraes do otimizador para uma determinada query. em vez de depender inteiramente de estimativas do otimizador para comparar planos de configuraes diferentes, a soluo baseia-se num algoritmo de seleo greedy que suporta vrios tipos de tcnicas de modelagem preditiva, desde tcnicas mais tradicionais a uma abordagem de deep learning. o sistema  avaliado experimentalmente com os workloads tpc-h e join ordering benchmark para medir o custo e os benefcios de adicionar aprendizagem automtica a otimizadores de queries tradicionais.']\n",
      "Keywords: ['database tuning', 'machine learning', 'query optimization', 'aprendizagem automtica', 'otimizao de queries', 'tuning de base de dados']\n",
      "\n",
      "Document 2 - Similarity: 0.5202\n",
      "Title: utilizao dos templates e modelos do django para desenvolver aplicaes web de elevado desempenho\n",
      "Authors: fernandes, joo miguel gonalves\n",
      "Abstract: ['this document describes the development of high performance web applications using django framework. initially, the operation and usage mode of django are introduced, as well as several web applications latency reduction techniques. the work carried out fo cused on the design, implementation and performance optimization of a web application, which consists of an article sharing system. the development process followed the scrum methodology. during development, several technologies were explored, such as memcached, celery and varnish, which enabled the implementation of certain performance optimi zation strategies. the latency of several operations was measured, before and after the application of optimization techniques, in order to ensure that one was moving in the right direction. the optimization of the applications performance was performed at various le vels, including the transfer of content across the network and the backend services. http caching, data compression and minification tecniques, as well as static content replication using content delivery networks, were used. partial update of the applications pages on the front-end and asynchronous processing techniques were applied. the database utili zation was optimized by creating indexes and by taking advantage of a nosql solution. memory caching strategies, with distinct granularities, were implemented to store templa tes and application objects. furthermore, asynchronous task queues were used to perform some costly operations. all of the aforementioned techniques favorably contributed to the web applications latency decrease. django only supports the application of some of these techniques, because it operates on the back-end. since performance must be optimized at various levels, it was necessary to use other tools besides django.', 'este documento descreve o desenvolvimento de aplicaes web de elevado desempenho com a framework django. inicialmente, apresenta-se o funcionamento e o modo de utiliza o do django, bem como diversas tcnicas de diminuio da latncia das aplicaes web. o trabalho realizado focou-se na conceo, implementao e otimizao do desempenho de uma aplicao web, que consiste num sistema de partilha de artigos. o processo de desenvolvimento seguiu a metodologia scrum. durante o desenvolvimento foram explo radas diversas tecnologias, tais como memcached, celery e varnish, que possibilitaram a implementao de determinadas estratgias de otimizao do desempenho. realizaram-se medies da latncia de diversas operaes, antes e aps a aplicao das estratgias de oti mizao, para garantir que se caminhava no sentido correto. a otimizao do desempenho da aplicao ocorreu a vrios nveis, incluindo a transferncia do contedo pela rede e os servios de back-end. utilizaram-se tcnicas como o caching http, bem como a compresso e minificao de informao e, ainda, a replicao de contedo esttico utilizando content delivery networks. aplicaram-se tcnicas de processamento assncrono e atualizao parcial das pginas da aplicao no front-end. otimizou-se a utilizao da base de dados, criando ndices e tirando partido de uma soluo nosql. implementaram-se estratgias de caching em memria com granularidades distintas, para armazenar templates e objetos gerados pela aplicao. recorreu-se ainda a filas assncronas de tarefas para a realizao de algumas operaes custosas. todas as tcnicas mencionadas contriburam favoravelmente para a di minuio da latncia da aplicao web. o django apenas suporta a aplicao de algumas destas tcnicas, j que opera no back-end. como o desempenho deve ser otimizado a vrios nveis, foi necessrio recorrer a outras ferramentas para alm do django.']\n",
      "Keywords: None\n",
      "\n",
      "Document 3 - Similarity: 0.5006\n",
      "Title: on the performance of webassembly\n",
      "Authors: macedo, joo gonalves de\n",
      "Abstract: ['the worldwide web has dramatically evolved in recent years. web pages are dynamic, expressed by pro grams written in common programming languages given rise to sophisticated web applications. thus, web browsers are almost operating systems, having to interpret/compile such programs and execute them. although javascript is widely used to express dynamic web pages, it has several shortcomings and performance inefficiencies. to overcome such limitations, major it powerhouses are developing a new portable and size/load efficient language: webassembly. in this dissertation, we conduct the first systematic study on the energy and run-time performance of webassembly and javascript on the web. we used micro-benchmarks and real applications to have more realistic results. the results show that webassembly, while still in its infancy, is starting to already outperform javascript, with much more room to grow. a statistical analysis indicates that webassembly produces significant performance differences compared to javascript. however, these differences differ between micro-benchmarks and real-world benchmarks. our results also show that webassembly improved energy efficiency by 30%, on average, and show how different webassembly behaviour is among three popular web browsers: google chrome, microsoft edge, and mozilla firefox. our findings indicate that webassembly is faster than javascript and even more energy-efficient. our benchmarking framework is also available to allow further research and replication.', 'a web evoluiu dramaticamente em todo o mundo nos ltimos anos. as pginas web so dinmicas, expressas por programas escritos em linguagens de programao comuns, dando origem a aplicativos web sofisticados. assim, os navegadores web so quase como sistemas operacionais, tendo que interpre tar/compilar tais programas e execut-los. embora o javascript seja amplamente usado para expressar pginas web dinmicas, ele tem vrias deficincias e ineficincias de desempenho. para superar tais limitaes, as principais potncias de ti esto a desenvolver uma nova linguagem porttil e eficiente em tamanho/carregamento: webassembly. nesta dissertao, conduzimos o primeiro estudo sistemtico sobre o desempenho da energia e do tempo de execuo do webassembly e javascript na web. usamos micro-benchmarks e aplicaes reais para obter resultados mais realistas. os resultados mostram que webassembly, embora ainda esteja na sua infncia, j est comea a superar o javascript, com muito mais espao para crescer. uma anlise estatstica indica que webassembly produz diferenas de desempenho significativas em relao ao javascript. no entanto, essas diferenas diferem entre micro-benchmarks e benchmarks de aplicaes reais. os nossos resultados tambm mostram que o webassembly melhorou a eficincia energtica em 30%, em mdia, e mostram como o comportamento do webassembly  diferente entre trs navegadores web populares: google chrome, microsoft edge e mozilla firefox. as nossas descobertas indicam que o webassembly  mais rpido que o javascript e ainda mais eficiente em termos de energia. a nossa benchmarking framework est disponvel para permitir pesquisas adicionais e replicao.']\n",
      "Keywords: ['energy efficiency', 'green software', 'web browsers', 'webassembly', 'eficincia energtica', 'navegadores web', 'software verde']\n",
      "\n",
      "================================================================================\n",
      "Query: 'machine learning applications'\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|| 32/32 [00:31<00:00,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 results:\n",
      "\n",
      "Document 1 - Similarity: 0.6996\n",
      "Title: in-vehicle object detection with yolo algorithm\n",
      "Authors: farinha, joo simes\n",
      "Abstract: ['with the growing computational power that we have at our disposal and the ever-increasing amount of data available the field of machine learning has given rise to deep learning, a subset of machine learning algorithms that have shown extraordinary results in a variety of applications from natural language processing to computer vision. in the field of computer vision, these algorithms have greatly improved the state-of-the-art accuracy in tasks associated with object recognition such as detection. this thesis makes use of one of these algorithms, specifically the yolo algorithm, as a basis in the development of a system capable of detecting objects laying inside a car cockpit. to this end a dataset is collected for the purpose of training the yolo algorithm on this task. a comparative analysis of the detection performance of the yolov2 and yolov3 architectures is performed.several experiments are performed by modifying the yolov3 architecture to attempt to improve its accuracy. specifically tests are performed in regards to network size, and the multiple outputs present in this network. explorative experiments are done in order to test the effect that parallel network might have on detection performance. lastly tests are done to try to find an optimal learning rate and batch size for our dataset on the new architectures.', 'com o crescente poder computacional que temos  nossa disposio e o aumento da quantidade dados a que temos acesso o campo de machine learning deu origem ao deep learning um subconjunto de algoritmos de machine learning que tm demonstrado resultados extraordinrios numa variedade de aplicaes desde processamento de linguagens naturais a viso por computador. no campo de viso por computador estes algoritmos tm levado a enormes progressos na correo de sistemas de deteo de objetos. nesta tese usamos um destes algoritmos, especificament o yolo, como base para desenvolver um sistema capaz de detetar objetos dentro de um carro. dado isto um dataset  recolhido com o propsito de treinar o algoritmo yolo nesta tarefa. uma analise comparativa da correo dos algoritmos yolov2 e yolov3 e realizada. vrias tcnicas relacionadas com a modificao da arquitetura yolov3 so exploradas para otimizar o sistema para o problema especifico de deteo a bordo de veculos. especificamente testes so realizados no contexto de tamanho da rede e dos mltiplos outputs presentes nesta rede. experiencias exploratrias so realizadas de forma a testar o efeito que redes parallelas podem ter na correo dos algoritmos. por fim testes so feitos para tentar encontrar learning rates e batch sizes apropriados para o nosso dataset nas novas arquiteturas.']\n",
      "Keywords: None\n",
      "\n",
      "Document 2 - Similarity: 0.6607\n",
      "Title: fault tolerant decentralized deep neural networks\n",
      "Authors: padro, joo carlos faria\n",
      "Abstract: ['machine learning is trending in computer science, especially deep learning. training algorithms that follow this approach to machine learning routinely deal with vast amounts of data. processing these enormous quantities of data requires complex computation tasks that can take a long time to produce results. distributing computation efforts across multiple machines makes sense in this context, as it allows conclusive results to be available in a shorter time frame. distributing the training of a deep neural network is not a trivial procedure. various architectures have been proposed, following two different paradigms. the most common one follows a centralized approach, where a centralized entity, broadly named parameter server, synchronizes and coordinates the updates generated by a number of workers. the alternative discards the centralized unit, assuming a decentralized architecture. the synchronization between the multiple workers is assured by communication techniques that average gradients between a node and its peers. high-end clusters are the ideal environment to deploy deep learning systems. low latency between nodes assures low idle times for workers, increasing the overall system performance. these setups, however, are expensive and are only available to a limited number of entities. on the other end, there is a continuous growth of edge devices with potentially vast amounts of available computational resources. in this dissertation, we aim to implement a fault tolerant decentralized deep neural net work training framework, capable of handling the high latency and unreliability characteristic of edge networks. to manage communication between nodes, we employ decentralized algorithms capable of estimating parameters globally', 'machine learning, mais especificamente deep learning,  um campo emergente nas cincias da computao. algoritmos de treino aplicados em deep learning lidam muito frequentemente com vastas quantidades de dados. processar estas enormes quantidades de dados requer operaes computacionais complexas que demoram demasiado tempo para produzir resultados. distribuir o esforo computacional por mltiplas mquinas faz todo o sentido neste contexto e permite um aumento significativo de desempenho. distribuir o mtodo de treino de uma rede neuronal no  um processo trivial. vrias arquiteturas tm sido propostas, seguindo dois diferentes paradigmas. o mais comum segue uma abordagem centralizada, onde uma entidade central, normalmente denominada de parameter server, sincroniza e coordena todas as atualizaes produzidas pelos workers. a alternativa passa por descartar a entidade centralizada, assumindo uma arquitetura descentralizada. a sincronizao entre workers  assegurada atravs de estratgias de comunicao descentralizadas. clusters de alta performance so o ambiente ideal para a implementao de sistemas de deep learning. a baixa latncia entre nodos assegura baixos perodos de inatividade nos workers, aumentando assim o rendimento do sistema. estas instalaes, contudo, so muito custosas, estando apenas disponveis para um pequeno nmero de entidades. por outro lado, o nmero de equipamentos nas extremidades da rede, com baixo aproveitamento de poder computacional, continua a crescer, o que torna o seu uso desejvel. nesta dissertao, visamos implementar um ambiente de treino de redes neuronais descentralizado e tolerante a faltas, apto a lidar com alta latncia nas comunicaes e baixa estabilidade nos nodos, caraterstica de redes na extremidade. para coordenar a comunicao entre os nodos, empregamos algoritmos de agregao, capazes de criar uma viso geral de parmetros numa topologia.']\n",
      "Keywords: ['distributed systems', 'machine learning', 'artificial intelligence', 'fault tolerance', 'sistemas distribudos', 'inteligncia artificial', 'tolerncia a faltas']\n",
      "\n",
      "Document 3 - Similarity: 0.6420\n",
      "Title: deeploy: a neural network computer vision tool (for the nvidia tegra tx2 embedded system)\n",
      "Authors: fernandes, joo pedro alves\n",
      "Abstract: ['machine learning (ml) gives a computer system the ability to perform a certain task without being explicitly programmed to do it. although ml is not a new topic in the field of computer science, these techniques have been gaining increasing popularity due to advances in hardware (especially gpus). more powerful hardware supports more efficient training and a more responsive end-system, once deployed. these algorithms have proven to be particularly effective in image processing and feature detection, namely with deep neural networks. in the context of a vehicle, autonomous or not, perceiving its external and internal environment enables the ability to detect and identify left behind objects, its misuse or other potentially dangerous situations. this captured data is relevant to trigger vehicle intelligent responses. bosch is currently developing a system that has these capabilities and plans to leverage deep learning approaches to implement it. this work aimed to test and evaluate the suitability of a given embedded device for the project. it also determined the best strategy to implement deep learning solutions in the device. the supplied test bed was a nvidia software development kit (sdk) system for the embedded nvidia jetson tx2 device with the system-on-chip (soc) parker, an heterogeneous computing chip with 2 denver-cores (a nvidia implementation of arm-64 architecture), 4 cortexa57-cores (also arm-64), 256 pascal gpu-cores and support for up to 6 video cameras. the sdk includes several software library packages, including for image processing and ml. with the goal of fully exploiting the embedded device compute capabilities, this work studied several inference frameworks, going as far as implementing an inference engine from scratch (named deeploy) that produces inferences based on two libraries provided by nvidia: cudnn and tensorrt. deeploy was evaluated against well known and established frameworks, namely tensorflow, pytorch and darknet, in terms of efficiency, resource management and overall ease of use, maintainability and flexibility. this work also exploited key performance related features available on the device, such as power modes, half-precision floating point computation and the implemented shared memory architecture between the gpu-cores and the cpu-cores.', 'machine learning d a um sistema informtico a capacidade de completar uma dada tarefa sem ser explicitamente programado para tal. apesar de machine learning no ser um tpico novo no campo da engenharia informtica, estas tcnicas tm-se tornado cada vez mais comuns devido a avanos no hardware (especialmente nos gpus). hardware mais computa-cionalmente capaz d origem a treinos mais eficientes e a sistemas em campo mais rpidos. este tipo de tcnicas, em especial redes neuronais, demonstraram-se eficazes no processa-mento de imagens e deteo de objetos. no contexto de um veculo, autnomo ou no, perceber o seu interior e o ambiente no qual este se insere  essencial para detetar objetos esquecidos, o uso indevido do mesmo ou outro tipo de situaes perigosas. esta informao  essencial para desencadear respostas inteligentes por parte do veculo. a bosch est atualmente a desenvolver um sistema com estas capacidades e para o implementar pretende utilizar solues baseadas em redes neu-ronais. com o projeto pretendeu-se testar e avaliar a aptido de um dado dispositivo embe-bido para este projeto. serviu tambm para determinar a melhor estratgia para se fazer a implementao de redes neuronais neste dispositivo. os testes foram feitos num kit de desenvolvimento da nvidia que consiste num nvidia jetson tx2 que contm um chip de computao heterogneo composto por 2 cores denver (implementao da nvidia da ar-quitetura arm-64), 4 cores cortexa57 (tambm arm-64), 256 cores gpu pascal e capacidade de se conectar at 6 camaras de vdeo. o kit de desenvolvimento inclui vrias bibliotecas de software para processamento de imagem e at para ml. com o objectivo de tirar total partido das capacidades computacionais do sistema em-bebido, este trabalho explorou vrias plataformas de inferncia, implementando mesmo um motor de raiz capaz de fazer inferncia recorrendo a duas bibliotecas desenvolvi-das pela nvidia: cudnn e tensorrt. foi tambm feita uma comparao entre as duas implementaes desenvolvidas e frameworks tradicionais como tensorflow, pytorch e dark-net no que toca a eficincia, facilidade de manuteno e flexibilidade. este trabalho ex-plorou tambm as features chave que esto relacionadas com performance disponibilizadas pelo dispositivo embebido, como modos de consumo de energia, computao numrica de virgula flutuante de meia preciso e a arquitetura de memria partilhada implementada entre os mltiplos cores arm-64 e os cuda-cores do gpu.']\n",
      "Keywords: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Example query\n",
    "queries = [\n",
    "    \"processamento de linguagem natural em portugus\",\n",
    "    \"web performance optimization\",\n",
    "    \"machine learning applications\"\n",
    "]\n",
    "\n",
    "# Test the retrieval function with each query\n",
    "for query in queries:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Query: '{query}'\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    try:\n",
    "        # Retrieve similar documents\n",
    "        results = retrieve(query, documents, top_k=3)\n",
    "        \n",
    "        # Display results\n",
    "        if results:\n",
    "            print(f\"Top {len(results)} results:\")\n",
    "            for i, (doc, sim) in enumerate(results, 1):\n",
    "                print(f\"\\nDocument {i} - Similarity: {sim:.4f}\")\n",
    "                print(f\"Title: {doc.get('dc.title', 'No title')}\")\n",
    "                print(f\"Authors: {doc.get('dc.contributor.author', 'Unknown')}\")\n",
    "                \n",
    "                abstract = doc.get('dc.description.abstract', 'No abstract')\n",
    "                if len(abstract) > 200:\n",
    "                    print(f\"Abstract: {abstract[:200]}...\")\n",
    "                else:\n",
    "                    print(f\"Abstract: {abstract}\")\n",
    "                    \n",
    "                print(f\"Keywords: {doc.get('dc.subject', 'None')}\")\n",
    "        else:\n",
    "            print(\"No results found for this query.\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error testing retrieval: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
